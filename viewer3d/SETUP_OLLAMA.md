# ğŸ¤– Setup Ollama para Avatar Conversacional

## ğŸ“¥ InstalaciÃ³n de Ollama

### Windows
```bash
# OpciÃ³n 1: Con winget
winget install Ollama.Ollama

# OpciÃ³n 2: Descargar instalador
# https://ollama.ai/download
```

### Verificar instalaciÃ³n
```bash
ollama --version
```

---

## ğŸš€ Iniciar Ollama

```bash
# Iniciar servicio (dejar corriendo en una terminal)
ollama serve
```

**Importante**: Dejar esta terminal abierta mientras usas el avatar.

---

## ğŸ“¦ Descargar Modelo Qwen3:1.7b

```bash
# Descargar modelo ultra-ligero (1.7B parÃ¡metros)
ollama pull qwen3:1.7b
```

### Â¿Por quÃ© Qwen3:1.7b?

âœ… **Ultra-ligero**: Solo 1.7B parÃ¡metros (~1GB)  
âœ… **Muy rÃ¡pido**: Respuestas en <1 segundo  
âœ… **Bajo consumo**: Funciona en laptops sin GPU  
âœ… **Buena calidad**: Optimizado para conversaciÃ³n  
âœ… **Multilenguaje**: Excelente en espaÃ±ol  

### ComparaciÃ³n de modelos

| Modelo | TamaÃ±o | RAM | Velocidad | Calidad |
|--------|--------|-----|-----------|---------|
| qwen3:1.7b | ~1.4GB | 2-4GB | âš¡âš¡âš¡ | â­â­â­â­ |
| phi-2 | ~1.7GB | 4GB | âš¡âš¡ | â­â­â­ |
| mistral:7b | ~4GB | 8GB | âš¡ | â­â­â­â­ |
| llama3:8b | ~4.7GB | 8GB | âš¡ | â­â­â­â­â­ |

---

## âœ… Verificar que funciona

```bash
# Listar modelos instalados
ollama list

# DeberÃ­a mostrar:
# NAME                ID              SIZE      MODIFIED
# qwen3:1.7b          abc123def       1.4 GB    2 minutes ago

# Probar el modelo
ollama run qwen3:1.7b "Hola, Â¿cÃ³mo estÃ¡s?"
```

---

## ğŸ—¿ Usar con el Avatar

1. **Iniciar Ollama**:
   ```bash
   ollama serve
   ```

2. **Abrir el visualizador**:
   ```bash
   cd viewer3d
   npm run dev
   ```

3. **En el navegador**:
   - Click en botÃ³n ğŸ—¿ (bottom-right)
   - Click en "Conectar"
   - Â¡Habla con el Moai!

---

## ğŸ”§ Troubleshooting

### Error: "Ollama no estÃ¡ disponible"

**SoluciÃ³n**:
```bash
# Verificar que Ollama estÃ¡ corriendo
curl http://localhost:11434/api/tags

# Si no responde, iniciar:
ollama serve
```

### Error: "Model not found"

**SoluciÃ³n**:
```bash
# Descargar el modelo
ollama pull qwen2.5:1.7b

# Verificar que se descargÃ³
ollama list
```

### Respuestas muy lentas

**SoluciÃ³n**:
```bash
# Usar modelo mÃ¡s pequeÃ±o
ollama pull qwen2.5:0.5b

# O ajustar temperatura en el cÃ³digo
# temperature: 0.5  (mÃ¡s rÃ¡pido, menos creativo)
```

### Respuestas en inglÃ©s

**SoluciÃ³n**: El system prompt ya estÃ¡ en espaÃ±ol. Si responde en inglÃ©s:
```bash
# Probar con:
ollama run qwen2.5:1.7b "Responde siempre en espaÃ±ol: Â¿QuÃ© es un Moai?"
```

---

## ğŸ¯ Modelos Alternativos

Si `qwen2.5:1.7b` no funciona bien, prueba:

### OpciÃ³n 1: Phi-2 (Microsoft)
```bash
ollama pull phi-2
```
- TamaÃ±o: ~1.7GB
- Muy bueno para conversaciÃ³n
- RÃ¡pido en CPU

### OpciÃ³n 2: Gemma:2b (Google)
```bash
ollama pull gemma:2b
```
- TamaÃ±o: ~1.4GB
- Optimizado para diÃ¡logo
- Excelente en espaÃ±ol

### OpciÃ³n 3: TinyLlama
```bash
ollama pull tinyllama
```
- TamaÃ±o: ~637MB
- El mÃ¡s ligero
- Calidad bÃ¡sica pero funcional

---

## ğŸ“Š Uso de Recursos

### Qwen2.5:1.7b
- **RAM**: 2-4GB
- **CPU**: Cualquier procesador moderno
- **GPU**: No requerida (pero ayuda)
- **Disco**: ~1GB

### Durante conversaciÃ³n
- **RAM adicional**: +500MB
- **CPU**: 20-40% (picos durante respuesta)
- **Latencia**: 500ms - 2s por respuesta

---

## ğŸš€ OptimizaciÃ³n

### Para mÃ¡xima velocidad
```bash
# Usar modelo mÃ¡s pequeÃ±o
ollama pull qwen2.5:0.5b

# O ajustar parÃ¡metros en cÃ³digo:
# temperature: 0.3  (menos creativo, mÃ¡s rÃ¡pido)
# maxTokens: 100    (respuestas mÃ¡s cortas)
```

### Para mejor calidad
```bash
# Usar modelo mÃ¡s grande
ollama pull mistral:7b

# O ajustar parÃ¡metros:
# temperature: 0.8  (mÃ¡s creativo)
# maxTokens: 300    (respuestas mÃ¡s elaboradas)
```

---

## ğŸ“ Comandos Ãštiles

```bash
# Ver modelos instalados
ollama list

# Eliminar modelo
ollama rm qwen2.5:1.7b

# Ver uso de recursos
ollama ps

# Detener Ollama
# Ctrl+C en la terminal donde corre ollama serve
```

---

## ğŸ“ Recursos

- [Ollama Website](https://ollama.ai/)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [Qwen2.5 Model Card](https://ollama.ai/library/qwen2.5)
- [Lista completa de modelos](https://ollama.ai/library)

---

## âœ… Checklist de Setup

- [ ] Ollama instalado (`ollama --version`)
- [ ] Ollama corriendo (`ollama serve`)
- [ ] Modelo descargado (`ollama list`)
- [ ] Modelo probado (`ollama run qwen2.5:1.7b "test"`)
- [ ] Visualizador corriendo (`npm run dev`)
- [ ] Avatar conectado (botÃ³n ğŸ—¿ â†’ Conectar)
- [ ] Primera conversaciÃ³n exitosa

---

**Â¡Listo para conversar con el Moai!** ğŸ—¿âœ¨
