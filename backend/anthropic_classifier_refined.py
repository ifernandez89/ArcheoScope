#!/usr/bin/env python3
"""
Clasificador Antropog√©nico Refinado - ArcheoScope
==================================================

AFINADO CR√çTICO: Separar origen vs actividad antropog√©nica.

El problema de la Esfinge:
- Origen antropog√©nico: ~95% (es una estructura humana)
- Actividad antropog√©nica: ~5% (no hay actividad humana reciente)
- Anomaly Score: 0.0% (no hay anomal√≠a detectable)

Esto NO es contradictorio - es arqueolog√≠a hist√≥rica.

FILOSOF√çA:
- anthropic_origin_probability: ¬øFue creado por humanos?
- anthropic_activity_probability: ¬øHay actividad humana reciente/actual?
- anomaly_score: ¬øHay desviaci√≥n estad√≠stica del entorno?

Una estructura antigua puede tener:
- Alto origen, baja actividad, baja anomal√≠a ‚Üí ARQUEOLOG√çA HIST√ìRICA
- Alto origen, alta actividad, alta anomal√≠a ‚Üí SITIO ACTIVO
- Bajo origen, baja actividad, alta anomal√≠a ‚Üí GEOMORFOLOG√çA INUSUAL
"""

import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from scipy import stats

@dataclass
class RefinedAnthropicInference:
    """
    Inferencia antropog√©nica refinada con separaci√≥n origen/actividad.
    """
    # SEPARACI√ìN CR√çTICA
    anthropic_origin_probability: float  # ¬øFue creado por humanos? (0-1)
    anthropic_activity_probability: float  # ¬øHay actividad humana actual? (0-1)
    
    # Intervalos de confianza SEPARADOS
    origin_confidence_interval: Tuple[float, float]
    activity_confidence_interval: Tuple[float, float]
    
    # Confianza general
    confidence: str  # "high", "medium", "low"
    
    # Razonamiento
    origin_reasoning: List[str]
    activity_reasoning: List[str]
    
    # Clasificaci√≥n de sitio
    site_classification: str  # "historical_structure", "active_site", "natural_formation", "uncertain"
    
    # M√©tricas de cobertura
    coverage_raw: float = 0.0
    coverage_effective: float = 0.0
    instruments_measured: int = 0
    instruments_available: int = 0
    
    # Modelo usado
    model_used: str = "refined_dual_axis_v1"


class RefinedAnthropicClassifier:
    """
    Clasificador antropog√©nico refinado que separa origen de actividad.
    
    Resuelve el problema de la Esfinge y estructuras hist√≥ricas.
    """
    
    def __init__(self):
        """Inicializar clasificador."""
        print("[REFINED CLASSIFIER] Inicializado con separaci√≥n origen/actividad", flush=True)
    
    def classify(self,
                 anomaly_score: float,
                 morphology: Dict[str, Any],
                 normalized_features: Dict[str, float],
                 raw_measurements: Dict[str, Any],
                 environment_type: str) -> RefinedAnthropicInference:
        """
        Clasificar sitio con separaci√≥n origen/actividad.
        
        Args:
            anomaly_score: Score de anomal√≠a (0-1)
            morphology: Resultado de an√°lisis morfol√≥gico
            normalized_features: Features normalizadas
            raw_measurements: Mediciones crudas
            environment_type: Tipo de ambiente
        
        Returns:
            RefinedAnthropicInference con probabilidades separadas
        """
        print("[REFINED CLASSIFIER] Clasificando con dual-axis...", flush=True)
        
        # =====================================================================
        # EJE 1: ORIGEN ANTROPOG√âNICO (¬øFue creado por humanos?)
        # =====================================================================
        
        origin_reasoning = []
        
        # Factores de ORIGEN (independientes de actividad actual)
        origin_factors = []
        
        # 1. Morfolog√≠a (cr√≠tico para origen)
        symmetry_score = morphology.get('symmetry_score', 0.0)
        edge_regularity = morphology.get('edge_regularity', 0.0)
        planarity = morphology.get('planarity', 0.0)
        
        # Morfolog√≠a es MUY indicativa de origen antropog√©nico
        # Si tienes alta simetr√≠a + regularidad + planaridad ‚Üí muy probable origen humano
        morphology_score = (symmetry_score * 0.4 + 
                           edge_regularity * 0.4 + 
                           planarity * 0.2)
        
        # BOOST si m√∫ltiples indicadores morfol√≥gicos son altos
        if symmetry_score > 0.6 and edge_regularity > 0.6:
            morphology_score = min(1.0, morphology_score * 1.3)  # +30% boost
            origin_reasoning.append(f"morfolog√≠a altamente regular (simetr√≠a {symmetry_score:.2f}, bordes {edge_regularity:.2f})")
        elif symmetry_score > 0.6:
            origin_reasoning.append(f"simetr√≠a geom√©trica ({symmetry_score:.2f})")
        
        if edge_regularity > 0.6:
            origin_reasoning.append(f"regularidad de bordes ({edge_regularity:.2f})")
        if planarity > 0.6:
            origin_reasoning.append(f"planaridad ({planarity:.2f})")
        
        origin_factors.append(morphology_score)
        
        # 2. Indicadores artificiales (MUY importante)
        artificial_indicators = morphology.get('artificial_indicators', [])
        if len(artificial_indicators) > 0:
            # Cada indicador artificial es evidencia fuerte
            indicator_score = min(1.0, 0.5 + len(artificial_indicators) * 0.15)
            origin_factors.append(indicator_score)
            origin_reasoning.append(f"indicadores artificiales: {', '.join(artificial_indicators)}")
        
        # 3. Contexto geomorfol√≥gico (NEGATIVO para origen)
        geomorphology_hint = morphology.get('geomorphology_hint', 'unknown')
        natural_formations = [
            'glacial_outwash', 'moraine', 'dune', 'wadi', 
            'lava_flow', 'erosion_pattern', 'natural_terrace'
        ]
        
        if any(nat in geomorphology_hint for nat in natural_formations):
            # Reducir probabilidad de origen antropog√©nico
            origin_factors.append(-0.3)
            origin_reasoning.append(f"geomorfolog√≠a natural: {geomorphology_hint}")
        
        # Calcular probabilidad de ORIGEN
        if len(origin_factors) > 0:
            origin_probability = np.mean(origin_factors)
            origin_probability = float(np.clip(origin_probability, 0, 1))
        else:
            origin_probability = 0.3  # Prior neutral
        
        # =====================================================================
        # EJE 2: ACTIVIDAD ANTROPOG√âNICA (¬øHay actividad humana actual?)
        # =====================================================================
        
        activity_reasoning = []
        
        # Factores de ACTIVIDAD (dependen de se√±ales actuales)
        activity_factors = []
        
        # 1. Anomal√≠a (cr√≠tico para actividad)
        # Alta anomal√≠a ‚Üí posible actividad reciente
        activity_factors.append(anomaly_score * 0.6)
        
        if anomaly_score > 0.3:
            activity_reasoning.append(f"anomal√≠a detectable ({anomaly_score:.2f})")
        elif anomaly_score < 0.1:
            activity_reasoning.append(f"sin anomal√≠a significativa ({anomaly_score:.2f})")
        
        # 2. Se√±ales t√©rmicas (actividad reciente)
        thermal_signals = []
        for key, value in normalized_features.items():
            if 'thermal' in key.lower() or 'lst' in key.lower():
                if abs(value) > 1.5:  # Desviaci√≥n t√©rmica significativa
                    thermal_signals.append(key)
        
        if len(thermal_signals) > 0:
            activity_factors.append(0.4)
            activity_reasoning.append(f"se√±ales t√©rmicas an√≥malas: {len(thermal_signals)}")
        else:
            activity_factors.append(-0.2)
            activity_reasoning.append("sin se√±ales t√©rmicas an√≥malas")
        
        # 3. Vegetaci√≥n (NDVI) - actividad agr√≠cola/manejo
        ndvi_signals = []
        for key, value in normalized_features.items():
            if 'ndvi' in key.lower():
                if abs(value) > 1.5:
                    ndvi_signals.append(key)
        
        if len(ndvi_signals) > 0 and environment_type not in ['desert', 'polar_ice']:
            activity_factors.append(0.3)
            activity_reasoning.append("patr√≥n de vegetaci√≥n an√≥malo")
        
        # 4. SAR (estructuras activas, movimiento)
        sar_signals = []
        for key, value in normalized_features.items():
            if 'sar' in key.lower():
                if abs(value) > 2.0:  # Alta desviaci√≥n SAR
                    sar_signals.append(key)
        
        if len(sar_signals) > 0:
            activity_factors.append(0.3)
            activity_reasoning.append("se√±al SAR an√≥mala (posible estructura activa)")
        
        # Calcular probabilidad de ACTIVIDAD
        if len(activity_factors) > 0:
            activity_probability = np.mean(activity_factors)
            activity_probability = float(np.clip(activity_probability, 0, 1))
        else:
            activity_probability = 0.1  # Prior bajo (mayor√≠a de sitios son hist√≥ricos)
        
        # =====================================================================
        # AJUSTES POR COBERTURA INSTRUMENTAL
        # =====================================================================
        
        # Calcular cobertura (mismo m√©todo que antes)
        instruments_measured = len([k for k in normalized_features.keys() 
                                   if 'zscore' in k and k not in ['mean_deviation', 'max_deviation', 'convergence_ratio']])
        instruments_available = raw_measurements.get('instruments_available', 5)
        coverage_raw = instruments_measured / instruments_available if instruments_available > 0 else 0.0
        
        # Cobertura efectiva (simplificada)
        coverage_effective = coverage_raw * 0.8  # Placeholder
        
        # Penalizaci√≥n por baja cobertura (afecta M√ÅS a actividad que a origen)
        if coverage_effective < 0.3:
            # Actividad es m√°s sensible a cobertura
            activity_probability *= 0.7
            activity_reasoning.append(f"‚ö†Ô∏è baja cobertura ({coverage_effective:.1%}) - actividad incierta")
            
            # Origen menos afectado (morfolog√≠a es m√°s robusta)
            origin_probability *= 0.9
            origin_reasoning.append(f"‚ö†Ô∏è baja cobertura ({coverage_effective:.1%})")
        
        # =====================================================================
        # CLASIFICACI√ìN DE SITIO
        # =====================================================================
        
        # Umbrales ajustados para mejor clasificaci√≥n
        if origin_probability > 0.55 and activity_probability < 0.3:
            site_classification = "historical_structure"
        elif origin_probability > 0.6 and activity_probability > 0.3:
            # Sitio con origen antropog√©nico y alguna actividad
            site_classification = "active_site"
        elif origin_probability < 0.4 and anomaly_score > 0.5:
            site_classification = "natural_anomaly"
        elif origin_probability < 0.4:
            site_classification = "natural_formation"
        else:
            site_classification = "uncertain"
        
        # =====================================================================
        # INTERVALOS DE CONFIANZA
        # =====================================================================
        
        # Intervalo m√°s amplio si hay baja cobertura
        ci_width = 0.15 if coverage_effective < 0.5 else 0.10
        
        origin_ci = (
            max(0.0, origin_probability - ci_width),
            min(1.0, origin_probability + ci_width)
        )
        
        activity_ci = (
            max(0.0, activity_probability - ci_width),
            min(1.0, activity_probability + ci_width)
        )
        
        # =====================================================================
        # CONFIANZA GENERAL
        # =====================================================================
        
        if coverage_effective > 0.7 and len(origin_reasoning) >= 2:
            confidence = "high"
        elif coverage_effective > 0.4:
            confidence = "medium"
        else:
            confidence = "low"
        
        # =====================================================================
        # LOGGING
        # =====================================================================
        
        print(f"[REFINED CLASSIFIER] üìä Resultados:", flush=True)
        print(f"  üèõÔ∏è  Origen antropog√©nico: {origin_probability:.1%} [{origin_ci[0]:.1%}, {origin_ci[1]:.1%}]", flush=True)
        print(f"  üî• Actividad antropog√©nica: {activity_probability:.1%} [{activity_ci[0]:.1%}, {activity_ci[1]:.1%}]", flush=True)
        print(f"  üìç Clasificaci√≥n: {site_classification}", flush=True)
        print(f"  üéØ Confianza: {confidence}", flush=True)
        print(f"  üì° Cobertura: {coverage_raw:.1%} raw, {coverage_effective:.1%} effective", flush=True)
        
        if len(origin_reasoning) == 0:
            origin_reasoning.append("sin indicadores claros de origen antropog√©nico")
        if len(activity_reasoning) == 0:
            activity_reasoning.append("sin se√±ales de actividad reciente")
        
        return RefinedAnthropicInference(
            anthropic_origin_probability=origin_probability,
            anthropic_activity_probability=activity_probability,
            origin_confidence_interval=origin_ci,
            activity_confidence_interval=activity_ci,
            confidence=confidence,
            origin_reasoning=origin_reasoning,
            activity_reasoning=activity_reasoning,
            site_classification=site_classification,
            coverage_raw=coverage_raw,
            coverage_effective=coverage_effective,
            instruments_measured=instruments_measured,
            instruments_available=instruments_available,
            model_used="refined_dual_axis_v1"
        )
