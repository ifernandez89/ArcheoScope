#!/usr/bin/env python3
"""
Territorial Inferential Multi-domain Tomography (TIMT) - SISTEMA COMPLETO
========================================================================

REVOLUCI√ìN CONCEPTUAL: Motor de Tomograf√≠a Territorial Inferencial
De "detector de sitios" a "explicador de territorios"

FLUJO CIENT√çFICO COMPLETO (3 CAPAS):
CAPA 0: Contexto antes de medir (TCP)
CAPA 1: Adquisici√≥n dirigida por hip√≥tesis
CAPA 2: Tomograf√≠a + evidencia + narrativa
CAPA 3: Transparencia + l√≠mites + comunicaci√≥n

RESULTADO: Sistema cient√≠ficamente honesto que promete coherencia, no certezas.
"""

import asyncio
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

from territorial_context_profile import TerritorialContextProfileSystem, TerritorialContextProfile, AnalysisObjective
from etp_generator import ETProfileGenerator
from etp_core import EnvironmentalTomographicProfile, BoundingBox
import os
from pathlib import Path

logger = logging.getLogger(__name__)

# HRM Imports
try:
    from hrm.hrm_runner import load_models as load_hrm_model, generate_response as generate_hrm_response
    HRM_AVAILABLE = True
except ImportError:
    HRM_AVAILABLE = False
    logger.warning("‚ö†Ô∏è HRM module not available")


class AnalysisMode(Enum):
    """Modos de an√°lisis territorial."""
    HYPOTHESIS_DRIVEN = "hypothesis_driven"    # Dirigido por hip√≥tesis (NUEVO)
    SENSOR_DRIVEN = "sensor_driven"           # Dirigido por sensores (TRADICIONAL)
    HYBRID = "hybrid"                         # H√≠brido

class EvidenceLevel(Enum):
    """Niveles de evidencia."""
    STRONG = "strong"           # Evidencia fuerte, m√∫ltiples fuentes
    MODERATE = "moderate"       # Evidencia moderada
    WEAK = "weak"              # Evidencia d√©bil
    CONTRADICTORY = "contradictory"  # Evidencia contradictoria
    INSUFFICIENT = "insufficient"    # Evidencia insuficiente

class CommunicationLevel(Enum):
    """Niveles de comunicaci√≥n de resultados."""
    TECHNICAL = "technical"     # T√©cnico especializado
    ACADEMIC = "academic"       # Acad√©mico riguroso
    GENERAL = "general"         # P√∫blico general
    INSTITUTIONAL = "institutional"  # Institucional

@dataclass
class HypothesisValidation:
    """Validaci√≥n de hip√≥tesis territorial."""
    
    hypothesis_id: str
    hypothesis_type: str
    
    # Evidencia por fuente
    sensorial_evidence: float      # 0-1
    geological_evidence: float     # 0-1
    hydrographic_evidence: float   # 0-1
    archaeological_evidence: float # 0-1
    human_traces_evidence: float   # 0-1
    
    # Evaluaci√≥n final
    overall_evidence_level: EvidenceLevel
    confidence_score: float        # 0-1
    
    # Contradicciones
    contradictions: List[str]
    supporting_factors: List[str]
    
    # Explicaci√≥n
    validation_explanation: str

@dataclass
class SystemTransparencyReport:
    """Reporte de transparencia del sistema."""
    
    # Proceso completo
    analysis_process: List[str]
    decisions_made: List[str]
    hypotheses_discarded: List[str]
    
    # Incertidumbres
    measurement_uncertainties: List[str]
    interpretation_uncertainties: List[str]
    
    # L√≠mites del sistema
    system_limitations: List[str]
    cannot_affirm: List[str]
    can_infer: List[str]
    
    # Recomendaciones
    validation_recommendations: List[str]
    future_work_suggestions: List[str]

    # M√©tricas cuantitativas de transparencia (con valores por defecto al final)
    hypotheses_evaluated: int = 0
    hypotheses_validated: int = 0
    hypotheses_rejected: int = 0

@dataclass
class TerritorialInferentialTomographyResult:
    """Resultado completo del an√°lisis tomogr√°fico territorial."""
    
    # Identificaci√≥n (campos requeridos primero)
    analysis_id: str
    territory_bounds: BoundingBox
    
    # CAPA 0: Contexto territorial (requerido)
    territorial_context: TerritorialContextProfile
    
    # CAPA 1: Perfil tomogr√°fico (requerido)
    tomographic_profile: EnvironmentalTomographicProfile
    
    # CAPA 3: Transparencia (requerido)
    transparency_report: SystemTransparencyReport
    
    # Campos con defaults
    analysis_timestamp: datetime = field(default_factory=datetime.now)
    
    # CAPA 2: Validaci√≥n de hip√≥tesis (opcional)
    hypothesis_validations: List[HypothesisValidation] = field(default_factory=list)
    
    # Comunicaci√≥n multinivel
    technical_summary: str = ""
    academic_summary: str = ""
    general_summary: str = ""
    institutional_summary: str = ""
    
    # M√©tricas finales
    territorial_coherence_score: float = 0.0  # Coherencia territorial general
    scientific_rigor_score: float = 0.0      # Rigor cient√≠fico del an√°lisis
    
    # HRM Output
    scientific_output: Dict[str, Any] = field(default_factory=dict)

class TerritorialInferentialTomographyEngine:
    """Motor de Tomograf√≠a Territorial Inferencial - SISTEMA COMPLETO."""
    
    def __init__(self, integrator_15_instruments):
        """
        Inicializar motor TIMT.
        
        Args:
            integrator_15_instruments: RealDataIntegratorV2 con 15 instrumentos
        """
        
        # Sistemas componentes
        self.tcp_system = TerritorialContextProfileSystem()
        self.etp_generator = ETProfileGenerator(integrator_15_instruments)
        
        # Inicializar HRM si est√° disponible
        self.hrm_model = None
        if HRM_AVAILABLE:
            try:
                self.hrm_model = load_hrm_model()
                logger.info("üß† HRM Model loaded in TIMT Engine")
            except Exception as e:
                logger.error(f"‚ùå Failed to load HRM model: {e}")
        
        # Configuraci√≥n del motor
        self.analysis_mode = AnalysisMode.HYPOTHESIS_DRIVEN  # NUEVO POR DEFECTO
        
        logger.info("üöÄ Territorial Inferential Tomography Engine initialized")
        logger.info("üß© MODO: Hypothesis-driven analysis (REVOLUCI√ìN CONCEPTUAL)")
    
    async def analyze_territory(self, lat_min: float, lat_max: float, lon_min: float, lon_max: float,
                               analysis_objective: AnalysisObjective = AnalysisObjective.EXPLORATORY,
                               analysis_radius_km: float = 5.0,
                               resolution_m: float = None,
                               communication_level: CommunicationLevel = CommunicationLevel.TECHNICAL) -> TerritorialInferentialTomographyResult:
        """
        An√°lisis territorial completo con flujo cient√≠fico de 3 capas.
        
        PROCESO REVOLUCIONARIO:
        CAPA 0: Contexto ‚Üí Hip√≥tesis ‚Üí Estrategia
        CAPA 1: Adquisici√≥n dirigida ‚Üí Tomograf√≠a
        CAPA 2: Validaci√≥n ‚Üí Transparencia ‚Üí Comunicaci√≥n
        
        Args:
            lat_min, lat_max, lon_min, lon_max: L√≠mites territoriales
            analysis_objective: Objetivo del an√°lisis
            analysis_radius_km: Radio de an√°lisis contextual
            resolution_m: Resoluci√≥n (si None, usa recomendaci√≥n TCP)
            communication_level: Nivel de comunicaci√≥n de resultados
            
        Returns:
            TerritorialInferentialTomographyResult completo
        """
        
        logger.info("üöÄ INICIANDO AN√ÅLISIS TERRITORIAL INFERENCIAL TOMOGR√ÅFICO")
        logger.info(f"üìç Territorio: [{lat_min:.4f}, {lat_max:.4f}] x [{lon_min:.4f}, {lon_max:.4f}]")
        logger.info(f"üéØ Objetivo: {analysis_objective.value}")
        logger.info(f"üì° Modo: {self.analysis_mode.value}")
        
        analysis_id = f"TIMT_{lat_min:.4f}_{lat_max:.4f}_{lon_min:.4f}_{lon_max:.4f}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ============================================================================
        # CAPA 0: CONTEXTO ANTES DE MEDIR (REVOLUCI√ìN CONCEPTUAL)
        # ============================================================================
        
        logger.info("üß© CAPA 0: GENERACI√ìN DE CONTEXTO TERRITORIAL (TCP)")
        
        tcp = await self.tcp_system.generate_tcp(
            lat_min, lat_max, lon_min, lon_max, analysis_objective, analysis_radius_km
        )
        
        # Usar resoluci√≥n recomendada por TCP si no se especifica
        if resolution_m is None:
            resolution_m = tcp.instrumental_strategy.recommended_resolution_m if tcp.instrumental_strategy else 50.0
        
        logger.info(f"‚úÖ TCP generado - {len(tcp.territorial_hypotheses)} hip√≥tesis territoriales")
        
        # ============================================================================
        # CAPA 1: ADQUISICI√ìN DIRIGIDA POR HIP√ìTESIS
        # ============================================================================
        
        logger.info("üõ∞Ô∏è CAPA 1: ADQUISICI√ìN DIRIGIDA Y TOMOGRAF√çA")
        
        # Crear bounding box 3D
        bounds = BoundingBox(
            lat_min=lat_min,
            lat_max=lat_max,
            lon_min=lon_min,
            lon_max=lon_max,
            depth_min=0.0,
            depth_max=-20.0
        )
        
        # Generar perfil tomogr√°fico (ahora dirigido por hip√≥tesis TCP)
        etp = await self.etp_generator.generate_etp(bounds, resolution_m)
        
        logger.info("‚úÖ Perfil tomogr√°fico generado")
        
        # ============================================================================
        # CAPA 2: VALIDACI√ìN DE HIP√ìTESIS Y EVIDENCIA
        # ============================================================================
        
        logger.info("üß† CAPA 2: VALIDACI√ìN DE HIP√ìTESIS TERRITORIALES")
        
        hypothesis_validations = self._validate_territorial_hypotheses(tcp, etp)
        
        logger.info(f"‚úÖ {len(hypothesis_validations)} hip√≥tesis validadas")
        
        # ============================================================================
        # CAPA 3: TRANSPARENCIA Y COMUNICACI√ìN
        # ============================================================================
        
        logger.info("üìã CAPA 3: GENERACI√ìN DE TRANSPARENCIA Y COMUNICACI√ìN")
        
        transparency_report = self._generate_transparency_report(tcp, etp, hypothesis_validations)
        
        # Comunicaci√≥n multinivel
        summaries = self._generate_multilevel_communication(
            tcp, etp, hypothesis_validations, transparency_report, communication_level
        )
        
        # M√©tricas finales
        territorial_coherence = self._calculate_territorial_coherence(tcp, etp, hypothesis_validations)
        scientific_rigor = self._calculate_scientific_rigor(tcp, etp, transparency_report)
        
        # ============================================================================
        # CAPA EXTRA: HRM ANALYSIS (Neural Visualization) & Honest Metrics
        # ============================================================================
        
        hrm_result = {}
        if self.hrm_model:
            logger.info("üß† EJECUTANDO AN√ÅLISIS HRM (High Resolution Morphology)")
            hrm_result = self._run_hrm_analysis(analysis_id, tcp, etp, hypothesis_validations)
        else:
            logger.warning("‚ö†Ô∏è HRM analysis skipped (model not available)")
            
        # Construir Scientific Output con m√©tricas de honestidad acad√©mica
        # Extraer instrumentos (esto es una simplificaci√≥n, en producci√≥n vendr√≠a del batch)
        available_instr = tcp.instrumental_strategy.priority_instruments if tcp.instrumental_strategy else ["Sentinel-2", "Sentinel-1", "DEM", "ICESat-2"]
        
        scientific_output = {
            "anthropic_origin_probability": etp.densidad_arqueologica_m3,
            "anthropic_activity_probability": 0.0, # Por ahora est√°tico hasta tener firma TAS/DIL mapeada
            "instrumental_anomaly_probability": etp.ess_superficial,
            "recommended_action": etp.get_archaeological_recommendation(),
            "notes": etp.narrative_explanation,
            "available_instruments": available_instr,
            "instruments_measured": len([i for i in available_instr if i]), # Simplificaci√≥n
            "coverage_raw": scientific_rigor, # Usar rigor como aproximaci√≥n de cobertura raw
            "hrm_analysis": hrm_result.get("hrm_analysis", {})
        }
        
        # ============================================================================
        # RESULTADO FINAL
        # ============================================================================
        
        result = TerritorialInferentialTomographyResult(
            analysis_id=analysis_id,
            territory_bounds=bounds,
            territorial_context=tcp,
            tomographic_profile=etp,
            hypothesis_validations=hypothesis_validations,
            transparency_report=transparency_report,
            technical_summary=summaries['technical'],
            academic_summary=summaries['academic'],
            general_summary=summaries['general'],
            institutional_summary=summaries['institutional'],
            territorial_coherence_score=territorial_coherence,
            scientific_rigor_score=scientific_rigor,
            scientific_output=scientific_output
        )
        
        logger.info("üéâ AN√ÅLISIS TERRITORIAL INFERENCIAL TOMOGR√ÅFICO COMPLETADO")
        logger.info(f"   üéØ Coherencia territorial: {territorial_coherence:.3f}")
        logger.info(f"   üî¨ Rigor cient√≠fico: {scientific_rigor:.3f}")
        logger.info(f"   üß† Hip√≥tesis validadas: {len([h for h in hypothesis_validations if h.overall_evidence_level in [EvidenceLevel.STRONG, EvidenceLevel.MODERATE]])}")
        
        return result
    
    def _validate_territorial_hypotheses(self, tcp: TerritorialContextProfile,
                                       etp: EnvironmentalTomographicProfile) -> List[HypothesisValidation]:
        """Validar hip√≥tesis territoriales contra evidencia tomogr√°fica."""
        
        validations = []
        
        for hypothesis in tcp.territorial_hypotheses:
            
            # Evidencia sensorial (del ETP)
            sensorial_evidence = etp.ess_volumetrico
            
            # Evidencia geol√≥gica
            geological_evidence = etp.geological_compatibility.gcs_score if etp.geological_compatibility else 0.5
            
            # Evidencia hidrogr√°fica
            hydrographic_evidence = etp.water_availability.settlement_viability if etp.water_availability else 0.5
            
            # Evidencia arqueol√≥gica externa
            archaeological_evidence = etp.external_consistency.ecs_score if etp.external_consistency else 0.5
            
            # Evidencia de trazas humanas
            human_traces_evidence = etp.territorial_use_profile.settlement_potential if etp.territorial_use_profile else 0.5
            
            # Evaluaci√≥n combinada
            evidence_scores = [
                sensorial_evidence,
                geological_evidence,
                hydrographic_evidence,
                archaeological_evidence,
                human_traces_evidence
            ]
            
            confidence_score = np.mean(evidence_scores)
            
            # Determinar nivel de evidencia
            if confidence_score > 0.8:
                evidence_level = EvidenceLevel.STRONG
            elif confidence_score > 0.6:
                evidence_level = EvidenceLevel.MODERATE
            elif confidence_score > 0.4:
                evidence_level = EvidenceLevel.WEAK
            else:
                evidence_level = EvidenceLevel.INSUFFICIENT
            
            # Identificar contradicciones y factores de soporte
            contradictions = []
            supporting_factors = []
            
            if sensorial_evidence < 0.3:
                contradictions.append("Baja evidencia sensorial")
            else:
                supporting_factors.append("Evidencia sensorial positiva")
            
            if geological_evidence > 0.7:
                supporting_factors.append("Contexto geol√≥gico favorable")
            elif geological_evidence < 0.3:
                contradictions.append("Contexto geol√≥gico desfavorable")
            
            if archaeological_evidence > 0.6:
                supporting_factors.append("Consistencia con sitios arqueol√≥gicos conocidos")
            
            # Explicaci√≥n de validaci√≥n
            explanation = f"Hip√≥tesis {hypothesis.hypothesis_type} con evidencia {evidence_level.value} (confianza: {confidence_score:.2f})"
            
            validation = HypothesisValidation(
                hypothesis_id=hypothesis.hypothesis_id,
                hypothesis_type=hypothesis.hypothesis_type,
                sensorial_evidence=sensorial_evidence,
                geological_evidence=geological_evidence,
                hydrographic_evidence=hydrographic_evidence,
                archaeological_evidence=archaeological_evidence,
                human_traces_evidence=human_traces_evidence,
                overall_evidence_level=evidence_level,
                confidence_score=confidence_score,
                contradictions=contradictions,
                supporting_factors=supporting_factors,
                validation_explanation=explanation
            )
            
            validations.append(validation)
        
        return validations
    
    def _generate_transparency_report(self, tcp: TerritorialContextProfile,
                                    etp: EnvironmentalTomographicProfile,
                                    validations: List[HypothesisValidation]) -> SystemTransparencyReport:
        """Generar reporte completo de transparencia del sistema."""
        
        # Proceso de an√°lisis
        analysis_process = [
            "1. Generaci√≥n de Contexto Territorial (TCP)",
            "2. Formulaci√≥n de hip√≥tesis territoriales",
            "3. Selecci√≥n instrumental dirigida por hip√≥tesis",
            "4. Adquisici√≥n de datos satelitales",
            "5. Generaci√≥n de perfil tomogr√°fico (ETP)",
            "6. Integraci√≥n de contextos adicionales",
            "7. Validaci√≥n cruzada de hip√≥tesis",
            "8. Evaluaci√≥n de coherencia territorial"
        ]
        
        # Decisiones tomadas
        decisions_made = [
            f"Modo de an√°lisis: {self.analysis_mode.value}",
            f"Resoluci√≥n seleccionada: {etp.resolution_m}m",
            f"Instrumentos prioritarios: {len(tcp.instrumental_strategy.priority_instruments) if tcp.instrumental_strategy else 0}",
            f"Hip√≥tesis evaluadas: {len(tcp.territorial_hypotheses)}"
        ]
        
        # Hip√≥tesis descartadas
        weak_hypotheses = [v for v in validations if v.overall_evidence_level in [EvidenceLevel.WEAK, EvidenceLevel.INSUFFICIENT]]
        hypotheses_discarded = [f"{h.hypothesis_type} (evidencia {h.overall_evidence_level.value})" for h in weak_hypotheses]
        
        # Incertidumbres de medici√≥n
        measurement_uncertainties = [
            "Profundidades inferidas, no medidas directamente",
            "Resoluci√≥n espacial limitada por sensores satelitales",
            "Condiciones atmosf√©ricas pueden afectar mediciones",
            "Cobertura temporal limitada de algunos instrumentos"
        ]
        
        # Incertidumbres de interpretaci√≥n
        interpretation_uncertainties = [
            "Anomal√≠as pueden tener origen natural o cultural",
            "Dataci√≥n relativa basada en patrones espaciales",
            "Funci√≥n territorial inferida de contexto",
            "Preservaci√≥n arqueol√≥gica variable seg√∫n condiciones"
        ]
        
        # L√≠mites del sistema
        system_limitations = tcp.known_limitations + [
            "No detecta estructuras espec√≠ficas individuales",
            "Limitado a evidencia indirecta y patrones",
            "Requiere validaci√≥n de campo para confirmaci√≥n",
            "Efectividad variable seg√∫n tipo de sitio"
        ]
        
        # Lo que NO puede afirmar
        cannot_affirm = [
            "Presencia confirmada de estructuras arqueol√≥gicas",
            "Dataci√≥n absoluta de anomal√≠as",
            "Funci√≥n espec√≠fica de estructuras detectadas",
            "Estado de preservaci√≥n exacto",
            "Significancia cultural espec√≠fica"
        ]
        
        # Lo que S√ç puede inferir
        can_infer = [
            "Patrones espaciales an√≥malos consistentes",
            "Coherencia territorial de anomal√≠as",
            "Compatibilidad con contexto arqueol√≥gico",
            "Potencial arqueol√≥gico relativo",
            "Priorizaci√≥n para investigaci√≥n de campo"
        ]
        
        # Recomendaciones de validaci√≥n
        validation_recommendations = [
            "Prospecci√≥n geof√≠sica de superficie",
            "Sondeos arqueol√≥gicos estrat√©gicos",
            "An√°lisis de materiales de superficie",
            "Documentaci√≥n fotogram√©trica detallada",
            "Consulta con arque√≥logos especialistas regionales"
        ]
        
        # Sugerencias de trabajo futuro
        future_work_suggestions = [
            "Integraci√≥n de datos LiDAR de alta resoluci√≥n",
            "An√°lisis temporal con series hist√≥ricas",
            "Validaci√≥n con excavaciones controladas",
            "Desarrollo de modelos predictivos regionales",
            "Integraci√≥n con bases de datos arqueol√≥gicas"
        ]
        
        # M√©tricas de hip√≥tesis
        valid_evidence_levels = [EvidenceLevel.STRONG, EvidenceLevel.MODERATE]
        hypotheses_evaluated = len(validations)
        hypotheses_validated = len([v for v in validations if v.overall_evidence_level in valid_evidence_levels])
        hypotheses_rejected = len([v for v in validations if v.overall_evidence_level not in valid_evidence_levels])

        return SystemTransparencyReport(
            analysis_process=analysis_process,
            decisions_made=decisions_made,
            hypotheses_discarded=hypotheses_discarded,
            hypotheses_evaluated=hypotheses_evaluated,
            hypotheses_validated=hypotheses_validated,
            hypotheses_rejected=hypotheses_rejected,
            measurement_uncertainties=measurement_uncertainties,
            interpretation_uncertainties=interpretation_uncertainties,
            system_limitations=system_limitations,
            cannot_affirm=cannot_affirm,
            can_infer=can_infer,
            validation_recommendations=validation_recommendations,
            future_work_suggestions=future_work_suggestions
        )
    
    def _generate_multilevel_communication(self, tcp: TerritorialContextProfile,
                                         etp: EnvironmentalTomographicProfile,
                                         validations: List[HypothesisValidation],
                                         transparency: SystemTransparencyReport,
                                         level: CommunicationLevel) -> Dict[str, str]:
        """Generar comunicaci√≥n multinivel de resultados."""
        
        # M√©tricas clave
        strong_hypotheses = [v for v in validations if v.overall_evidence_level == EvidenceLevel.STRONG]
        moderate_hypotheses = [v for v in validations if v.overall_evidence_level == EvidenceLevel.MODERATE]
        
        # Resumen t√©cnico
        technical = f"""
AN√ÅLISIS TERRITORIAL INFERENCIAL TOMOGR√ÅFICO
============================================

TERRITORIO: {tcp.territory_bounds}
OBJETIVO: {tcp.analysis_objective.value}
ESS VOLUM√âTRICO: {etp.ess_volumetrico:.3f}
COHERENCIA 3D: {etp.coherencia_3d:.3f}

HIP√ìTESIS VALIDADAS:
- Evidencia fuerte: {len(strong_hypotheses)}
- Evidencia moderada: {len(moderate_hypotheses)}

CONTEXTOS INTEGRADOS:
- Geol√≥gico: {etp.geological_context.dominant_lithology.value if etp.geological_context else 'N/A'}
- Hidrogr√°fico: {len(etp.hydrographic_features)} caracter√≠sticas
- Arqueol√≥gico externo: {len(etp.external_sites)} sitios
- Trazas humanas: {len(etp.human_traces)} trazas

LIMITACIONES: {len(transparency.system_limitations)} identificadas
RECOMENDACIONES: {len(transparency.validation_recommendations)} sugeridas
        """.strip()
        
        # Resumen acad√©mico
        academic = f"""
Este an√°lisis territorial aplic√≥ tomograf√≠a inferencial multidominio para evaluar {len(tcp.territorial_hypotheses)} hip√≥tesis territoriales. 
El sistema integr√≥ evidencia sensorial (ESS: {etp.ess_volumetrico:.3f}), contexto geol√≥gico (GCS: {etp.geological_compatibility.gcs_score if etp.geological_compatibility else 'N/A'}), 
validaci√≥n arqueol√≥gica externa (ECS: {etp.external_consistency.ecs_score if etp.external_consistency else 'N/A'}), y an√°lisis de trazas humanas.

Resultados: {len(strong_hypotheses)} hip√≥tesis con evidencia fuerte, {len(moderate_hypotheses)} con evidencia moderada. 
La coherencia territorial ({etp.coherencia_3d:.3f}) sugiere patrones espaciales consistentes que requieren validaci√≥n de campo.

Limitaciones: El sistema infiere patrones territoriales pero no confirma estructuras espec√≠ficas. 
Se recomienda prospecci√≥n geof√≠sica y sondeos arqueol√≥gicos para validaci√≥n.
        """.strip()
        
        # Resumen general
        general = f"""
Se analiz√≥ un territorio usando tecnolog√≠a satelital avanzada y inteligencia artificial para identificar posibles sitios arqueol√≥gicos.

El sistema encontr√≥ {len(strong_hypotheses + moderate_hypotheses)} √°reas de inter√©s arqueol√≥gico con diferentes niveles de evidencia. 
Se integraron datos geol√≥gicos, hidrogr√°ficos y de actividad humana hist√≥rica para una evaluaci√≥n completa.

Los resultados sugieren potencial arqueol√≥gico que requiere investigaci√≥n de campo para confirmaci√≥n. 
El an√°lisis proporciona una gu√≠a cient√≠fica para priorizar futuras excavaciones.
        """.strip()
        
        # Resumen institucional
        institutional = f"""
INFORME EJECUTIVO - AN√ÅLISIS TERRITORIAL ARQUEOL√ìGICO

TERRITORIO ANALIZADO: {tcp.territory_bounds}
METODOLOG√çA: Tomograf√≠a Territorial Inferencial con 15 instrumentos satelitales
OBJETIVO: {tcp.analysis_objective.value}

RESULTADOS PRINCIPALES:
‚Ä¢ {len(strong_hypotheses)} √°reas con evidencia arqueol√≥gica fuerte
‚Ä¢ {len(moderate_hypotheses)} √°reas con evidencia moderada
‚Ä¢ Coherencia territorial: {etp.coherencia_3d:.3f}/1.0
‚Ä¢ Potencial de preservaci√≥n: {tcp.preservation_potential.value}

RECOMENDACIONES:
‚Ä¢ Prospecci√≥n geof√≠sica en √°reas prioritarias
‚Ä¢ Sondeos arqueol√≥gicos estrat√©gicos
‚Ä¢ Consulta con especialistas regionales

LIMITACIONES: An√°lisis basado en evidencia indirecta. Requiere validaci√≥n de campo.
CONFIANZA CIENT√çFICA: Sistema transparente con limitaciones documentadas.
        """.strip()
        
        return {
            'technical': technical,
            'academic': academic,
            'general': general,
            'institutional': institutional
        }
    
    def _calculate_territorial_coherence(self, tcp: TerritorialContextProfile,
                                       etp: EnvironmentalTomographicProfile,
                                       validations: List[HypothesisValidation]) -> float:
        """Calcular coherencia territorial general."""
        
        coherence_factors = []
        
        # Coherencia tomogr√°fica 3D
        coherence_factors.append(etp.coherencia_3d)
        
        # Coherencia de hip√≥tesis
        if validations:
            hypothesis_coherence = np.mean([v.confidence_score for v in validations])
            coherence_factors.append(hypothesis_coherence)
        
        # Coherencia contextual
        context_scores = []
        if etp.geological_compatibility:
            context_scores.append(etp.geological_compatibility.gcs_score)
        if etp.external_consistency:
            context_scores.append(etp.external_consistency.ecs_score)
        if etp.water_availability:
            context_scores.append(etp.water_availability.settlement_viability)
        
        if context_scores:
            context_coherence = np.mean(context_scores)
            coherence_factors.append(context_coherence)
        
        return np.mean(coherence_factors) if coherence_factors else 0.5
    
    def _calculate_scientific_rigor(self, tcp: TerritorialContextProfile,
                                  etp: EnvironmentalTomographicProfile,
                                  transparency: SystemTransparencyReport) -> float:
        """Calcular rigor cient√≠fico del an√°lisis."""
        
        rigor_factors = []
        
        # Completitud del contexto
        context_completeness = 0.0
        if tcp.geological_context:
            context_completeness += 0.25
        if tcp.hydrographic_features:
            context_completeness += 0.25
        if tcp.external_archaeological_sites:
            context_completeness += 0.25
        if tcp.known_human_traces:
            context_completeness += 0.25
        
        rigor_factors.append(context_completeness)
        
        # Transparencia del proceso
        transparency_score = min(1.0, len(transparency.analysis_process) / 8.0)
        rigor_factors.append(transparency_score)
        
        # Documentaci√≥n de limitaciones
        limitations_score = min(1.0, len(transparency.system_limitations) / 5.0)
        rigor_factors.append(limitations_score)
        
        # Validaci√≥n cruzada
        if etp.external_consistency and etp.geological_compatibility:
            rigor_factors.append(0.8)  # Bonus por validaci√≥n cruzada
        
        return np.mean(rigor_factors) if rigor_factors else 0.5

    def _run_hrm_analysis(self, analysis_id: str, tcp: TerritorialContextProfile,
                        etp: EnvironmentalTomographicProfile,
                        validations: List[HypothesisValidation]) -> Dict[str, Any]:
        """Ejecutar an√°lisis HRM y generar visualizaci√≥n neural."""
        
        try:
            # 1. Preparar pregunta para HRM
            strongest_hypothesis = "No hypothesis"
            if validations:
                # Buscar la mejor validada
                best = max(validations, key=lambda x: x.confidence_score)
                strongest_hypothesis = f"{best.hypothesis_type} (confianza: {best.confidence_score:.2f})"
            
            question = (
                f"Analizar coherencia territorial en {tcp.territory_bounds}. "
                f"Contexto: {tcp.geological_context.dominant_lithology.value if tcp.geological_context else 'Unknown'}. "
                f"ESS Volum√©trico: {etp.ess_volumetrico:.3f}. "
                f"Hip√≥tesis principal: {strongest_hypothesis}."
            )
            
            # 2. Configurar path de visualizaci√≥n
            # Asegurar que el directorio existe
            maps_dir = Path("anomaly_maps")
            maps_dir.mkdir(exist_ok=True)
            
            filename = f"hrm_viz_{analysis_id}.png"
            viz_path = maps_dir / filename
            
            # 3. Ejecutar HRM
            response_json = generate_hrm_response(
                question=question,
                hrm_model=self.hrm_model,
                temperature=0.3,
                mode="scientific_strict",
                visualize_path=str(viz_path)
            )
            
            # 4. Procesar respuesta
            # Si response_json es string (porque fall√≥ el parseo JSON en HRM u otro motivo), empaquetarlo
            if isinstance(response_json, str):
                result = {
                    "raw_output": response_json,
                    "analisis_morfologico": "An√°lisis textual generado.",
                    "hipotesis_antropica": "Ver raw output.",
                    "hipotesis_natural_alternativa": "Ver raw output.",
                    "nivel_incertidumbre": "Indeterminado"
                }
            else:
                result = response_json
            
            # 5. Agregar URL de visualizaci√≥n (ser√° servida por /anomaly-map/{filename})
            # El frontend espera 'visualizacion_neural'
            # Usamos una URL relativa que el frontend pueda resolver
            # Si el frontend est√° en otro puerto, podr√≠a necesitar la URL completa del backend
            # Por ahora asumimos que el backend sirve esto en /anomaly-map/
            
            # Construir URL absoluta si es posible, o relativa
            API_URL = os.getenv("VITE_API_URL", "http://localhost:8003")
            result["visualizacion_neural"] = f"{API_URL}/anomaly-map/{filename}"
            
            logger.info(f"‚úÖ HRM Analysis complete. Viz: {filename}")
            
            return {
                "hrm_analysis": result
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in HRM analysis: {e}", exc_info=True)
            return {
                "error": str(e),
                "hrm_analysis": {}
            }