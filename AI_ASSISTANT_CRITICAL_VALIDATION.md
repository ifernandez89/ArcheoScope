# Validaci√≥n Cr√≠tica del Asistente de IA - ArcheoScope

## Fecha: 24 de Enero de 2026

---

## PROBLEMA IDENTIFICADO

El asistente de IA **ES CR√çTICO** para el an√°lisis arqueol√≥gico, pero el sistema no informaba claramente al usuario cuando fallaba la conexi√≥n.

### S√≠ntomas Anteriores
```
WARNING:ai.archaeological_assistant:‚ùå Ning√∫n proveedor de IA disponible
INFO:ai.archaeological_assistant:  - Disponible: ‚ùå
```

El sistema continuaba funcionando pero generaba errores HTTP 500 sin explicaci√≥n clara.

---

## SOLUCI√ìN IMPLEMENTADA

### 1. Mensajes de Error Mejorados en `archaeological_assistant.py`

**ANTES**:
```python
logger.warning("‚ö†Ô∏è Ning√∫n proveedor de IA disponible")
logger.info("üí° El sistema detecta anomal√≠as sin IA")
return False
```

**DESPU√âS**:
```python
logger.error("‚ùå CR√çTICO: Ning√∫n proveedor de IA disponible")
logger.error("‚ùå El asistente de IA es NECESARIO para an√°lisis arqueol√≥gico riguroso")
logger.error("‚ùå Por favor verifica:")
logger.error("   1. OPENROUTER_API_KEY est√° configurada en .env.local")
logger.error("   2. El modelo est√° disponible en OpenRouter")
logger.error("   3. Tienes conexi√≥n a internet")
logger.error("   4. O inicia Ollama con: ollama run phi4-mini-reasoning")
return False
```

### 2. Validaci√≥n en Inicializaci√≥n del Sistema (`main.py`)

Agregado en `initialize_system()`:

```python
# VALIDACI√ìN CR√çTICA: Verificar que la IA est√° disponible
if not system_components['ai_assistant'].is_available:
    logger.error("="*80)
    logger.error("‚ùå CR√çTICO: ASISTENTE DE IA NO DISPONIBLE")
    logger.error("="*80)
    logger.error("El asistente de IA es NECESARIO para an√°lisis arqueol√≥gico riguroso.")
    logger.error("")
    logger.error("SOLUCIONES:")
    logger.error("  1. Verifica OPENROUTER_API_KEY en .env.local")
    logger.error("  2. Verifica que el modelo est√© disponible en OpenRouter")
    logger.error("  3. Verifica conexi√≥n a internet")
    logger.error("  4. O inicia Ollama: ollama run phi4-mini-reasoning")
    logger.error("")
    logger.error("El sistema continuar√° pero las explicaciones arqueol√≥gicas ser√°n limitadas.")
    logger.error("="*80)
else:
    logger.info("‚úÖ Asistente de IA disponible y funcionando correctamente")
```

### 3. Validaci√≥n en Endpoint `/analyze`

Agregado al inicio del endpoint:

```python
# ‚ö†Ô∏è VALIDACI√ìN CR√çTICA: Verificar que la IA est√° disponible
ai_assistant = system_components.get('ai_assistant')
if not ai_assistant or not ai_assistant.is_available:
    logger.error("=" * 80)
    logger.error("‚ùå CR√çTICO: ASISTENTE DE IA NO DISPONIBLE")
    logger.error("=" * 80)
    logger.error("El an√°lisis arqueol√≥gico requiere el asistente de IA para interpretaciones rigurosas.")
    logger.error("")
    logger.error("SOLUCIONES:")
    logger.error("  1. Verifica OPENROUTER_API_KEY en .env.local")
    logger.error("  2. Verifica que el modelo est√© disponible")
    logger.error("  3. Verifica conexi√≥n a internet")
    logger.error("  4. O inicia Ollama: ollama run phi4-mini-reasoning")
    logger.error("=" * 80)
    
    raise HTTPException(
        status_code=503,
        detail={
            "error": "AI_ASSISTANT_UNAVAILABLE",
            "message": "El asistente de IA no est√° disponible. El an√°lisis arqueol√≥gico requiere IA para interpretaciones cient√≠ficas rigurosas.",
            "solutions": [
                "Verifica OPENROUTER_API_KEY en .env.local",
                "Verifica que el modelo est√© disponible en OpenRouter",
                "Verifica conexi√≥n a internet",
                "O inicia Ollama: ollama run phi4-mini-reasoning"
            ],
            "impact": "No se pueden generar explicaciones arqueol√≥gicas cient√≠ficas sin IA"
        }
    )
```

### 4. Mensajes de Diagn√≥stico Mejorados

El m√©todo `_check_availability()` ahora proporciona diagn√≥sticos espec√≠ficos:

```python
if response.status_code == 200:
    logger.info(f"‚úÖ OpenRouter disponible con {self.openrouter_model}")
    return True
elif response.status_code == 401:
    logger.warning(f"‚ö†Ô∏è OpenRouter: API key inv√°lida o expirada")
elif response.status_code == 404:
    logger.warning(f"‚ö†Ô∏è OpenRouter: Modelo {self.openrouter_model} no encontrado")
else:
    logger.warning(f"‚ö†Ô∏è OpenRouter error: HTTP {response.status_code}")
```

Y para errores de conexi√≥n:

```python
except requests.exceptions.Timeout:
    logger.warning(f"‚ö†Ô∏è OpenRouter: Timeout (red lenta o servicio no responde)")
except requests.exceptions.ConnectionError:
    logger.warning(f"‚ö†Ô∏è OpenRouter: Error de conexi√≥n (sin internet?)")
```

---

## CONFIGURACI√ìN CORRECTA

### Archivo `.env.local`

```bash
# OpenRouter API Configuration
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxx

# Modelo recomendado - Gemini 2.0 Flash Experimental (gratuito)
OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free

# Configuraci√≥n de providers
OLLAMA_ENABLED=false
OPENROUTER_ENABLED=true

# Configuraci√≥n de timeouts
AI_TIMEOUT_SECONDS=30
AI_MAX_TOKENS=300
```

### Modelos Recomendados en OpenRouter

1. **google/gemini-2.0-flash-exp:free** (Recomendado - Gratuito)
2. **google/gemini-flash-1.5** (Alternativa)
3. **anthropic/claude-3-haiku** (Alternativa de pago)

---

## RESULTADO

### Mensajes Claros al Usuario

**Al iniciar el sistema**:
```
================================================================================
‚ùå CR√çTICO: ASISTENTE DE IA NO DISPONIBLE
================================================================================
El asistente de IA es NECESARIO para an√°lisis arqueol√≥gico riguroso.

SOLUCIONES:
  1. Verifica OPENROUTER_API_KEY en .env.local
  2. Verifica que el modelo est√© disponible en OpenRouter
  3. Verifica conexi√≥n a internet
  4. O inicia Ollama: ollama run phi4-mini-reasoning

El sistema continuar√° pero las explicaciones arqueol√≥gicas ser√°n limitadas.
================================================================================
```

**Al intentar analizar sin IA**:
```
HTTP 503 Service Unavailable
{
  "error": "AI_ASSISTANT_UNAVAILABLE",
  "message": "El asistente de IA no est√° disponible...",
  "solutions": [...],
  "impact": "No se pueden generar explicaciones arqueol√≥gicas cient√≠ficas sin IA"
}
```

---

## VERIFICACI√ìN

### Paso 1: Verificar Estado de la IA

```bash
python run_archeoscope.py
```

Buscar en los logs:
- ‚úÖ `‚úÖ OpenRouter disponible con google/gemini-2.0-flash-exp:free`
- ‚úÖ `‚úÖ Asistente de IA disponible y funcionando correctamente`

O:
- ‚ùå `‚ùå CR√çTICO: ASISTENTE DE IA NO DISPONIBLE`

### Paso 2: Probar Endpoint

```bash
curl -X POST http://localhost:8002/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "lat_min": 29.97,
    "lat_max": 29.98,
    "lon_min": 31.13,
    "lon_max": 31.14,
    "region_name": "Test Giza"
  }'
```

**Si IA no disponible**: HTTP 503 con mensaje claro
**Si IA disponible**: HTTP 200 con an√°lisis completo

---

## CAUSAS COMUNES DE FALLO

### 1. API Key Inv√°lida o Expirada
**S√≠ntoma**: `‚ö†Ô∏è OpenRouter: API key inv√°lida o expirada`
**Soluci√≥n**: Regenerar API key en https://openrouter.ai/keys

### 2. Modelo No Encontrado
**S√≠ntoma**: `‚ö†Ô∏è OpenRouter: Modelo google/gemini-xxx no encontrado`
**Soluci√≥n**: Cambiar a modelo disponible en `.env.local`

### 3. Sin Conexi√≥n a Internet
**S√≠ntoma**: `‚ö†Ô∏è OpenRouter: Error de conexi√≥n (sin internet?)`
**Soluci√≥n**: Verificar conexi√≥n de red

### 4. Timeout
**S√≠ntoma**: `‚ö†Ô∏è OpenRouter: Timeout (red lenta o servicio no responde)`
**Soluci√≥n**: Aumentar `AI_TIMEOUT_SECONDS` en `.env.local`

### 5. Ollama No Corriendo
**S√≠ntoma**: `‚ö†Ô∏è Ollama: No est√° corriendo en http://localhost:11434`
**Soluci√≥n**: `ollama run phi4-mini-reasoning`

---

## IMPACTO

### SIN IA (Antes)
- ‚ùå Errores HTTP 500 sin explicaci√≥n
- ‚ùå Usuario confundido sobre qu√© fall√≥
- ‚ùå Sistema parec√≠a roto

### CON IA (Despu√©s)
- ‚úÖ Mensajes de error claros y accionables
- ‚úÖ Usuario sabe exactamente qu√© hacer
- ‚úÖ Sistema informa estado correctamente

---

## ARCHIVOS MODIFICADOS

1. `backend/ai/archaeological_assistant.py`
   - Mensajes de error mejorados
   - Diagn√≥sticos espec√≠ficos por tipo de error

2. `backend/api/main.py`
   - Validaci√≥n en `initialize_system()`
   - Validaci√≥n en endpoint `/analyze`
   - HTTP 503 con detalles cuando IA no disponible

3. `.env.local`
   - Modelo actualizado a `google/gemini-2.0-flash-exp:free`

---

## CONCLUSI√ìN

El asistente de IA es **CR√çTICO** para ArcheoScope. Ahora el sistema:

1. ‚úÖ Informa claramente cuando la IA no est√° disponible
2. ‚úÖ Proporciona soluciones espec√≠ficas al usuario
3. ‚úÖ Bloquea an√°lisis si la IA no funciona (HTTP 503)
4. ‚úÖ Muestra diagn√≥sticos detallados en logs

**El usuario siempre sabr√° por qu√© falla y c√≥mo solucionarlo.**

---

**√öltima actualizaci√≥n**: 2026-01-24  
**Versi√≥n**: 1.0.0  
**Estado**: ‚úÖ VALIDACI√ìN CR√çTICA IMPLEMENTADA
