#!/usr/bin/env python3
"""
Enriquecer BD con anÃ¡lisis de sitios arqueolÃ³gicos icÃ³nicos.

SITIOS A ANALIZAR:
1. ğŸ—¿ Machu Picchu, PerÃº
2. ğŸª Giza/Esfinge, Egipto
3. ğŸŒ€ Nazca, PerÃº
4. ğŸ›ï¸ Angkor Wat, Camboya
5. ğŸº Petra, Jordania
6. ğŸ—¼ TeotihuacÃ¡n, MÃ©xico
7. ğŸ° Stonehenge, UK
8. ğŸŒ‹ Pompeya, Italia
9. ğŸ›ï¸ AcrÃ³polis, Grecia
10. ğŸœï¸ ChichÃ©n ItzÃ¡, MÃ©xico

Objetivo: Poblar BD con anÃ¡lisis cientÃ­ficos completos usando:
- Pipeline cientÃ­fico refinado
- Explanatory Strangeness Score
- Ajustes quirÃºrgicos implementados
"""

import requests
import json
import time
from typing import Dict, List

# ConfiguraciÃ³n
API_BASE_URL = "http://localhost:8002"

# Sitios arqueolÃ³gicos icÃ³nicos con coordenadas reales
ICONIC_SITES = [
    {
        "name": "Machu Picchu",
        "country": "PerÃº",
        "lat": -13.1631,
        "lon": -72.5450,
        "environment": "mountain",
        "description": "Ciudad inca del siglo XV en los Andes peruanos",
        "expected_ess": "very_high"
    },
    {
        "name": "PirÃ¡mides de Giza",
        "country": "Egipto",
        "lat": 29.9792,
        "lon": 31.1342,
        "environment": "desert",
        "description": "Complejo de pirÃ¡mides del Antiguo Egipto",
        "expected_ess": "high"
    },
    {
        "name": "LÃ­neas de Nazca",
        "country": "PerÃº",
        "lat": -14.7390,
        "lon": -75.1300,
        "environment": "desert",
        "description": "Geoglifos precolombinos en el desierto de Nazca",
        "expected_ess": "very_high"
    },
    {
        "name": "Angkor Wat",
        "country": "Camboya",
        "lat": 13.4125,
        "lon": 103.8670,
        "environment": "tropical_forest",
        "description": "Complejo de templos jemer del siglo XII",
        "expected_ess": "high"
    },
    {
        "name": "Petra",
        "country": "Jordania",
        "lat": 30.3285,
        "lon": 35.4444,
        "environment": "desert",
        "description": "Ciudad nabatea tallada en roca",
        "expected_ess": "high"
    },
    {
        "name": "TeotihuacÃ¡n",
        "country": "MÃ©xico",
        "lat": 19.6925,
        "lon": -98.8438,
        "environment": "highland",
        "description": "Ciudad mesoamericana con pirÃ¡mides monumentales",
        "expected_ess": "high"
    },
    {
        "name": "Stonehenge",
        "country": "Reino Unido",
        "lat": 51.1789,
        "lon": -1.8262,
        "environment": "grassland",
        "description": "Monumento megalÃ­tico neolÃ­tico",
        "expected_ess": "medium"
    },
    {
        "name": "Pompeya",
        "country": "Italia",
        "lat": 40.7489,
        "lon": 14.4839,
        "environment": "urban",
        "description": "Ciudad romana sepultada por erupciÃ³n del Vesubio",
        "expected_ess": "medium"
    },
    {
        "name": "AcrÃ³polis de Atenas",
        "country": "Grecia",
        "lat": 37.9715,
        "lon": 23.7257,
        "environment": "urban",
        "description": "Ciudadela de la antigua Atenas",
        "expected_ess": "high"
    },
    {
        "name": "ChichÃ©n ItzÃ¡",
        "country": "MÃ©xico",
        "lat": 20.6843,
        "lon": -88.5678,
        "environment": "tropical_forest",
        "description": "Ciudad maya con pirÃ¡mide de KukulkÃ¡n",
        "expected_ess": "high"
    }
]

def analyze_site(site: Dict) -> Dict:
    """
    Analizar un sitio arqueolÃ³gico usando el endpoint cientÃ­fico.
    
    Args:
        site: Diccionario con datos del sitio
    
    Returns:
        Resultado del anÃ¡lisis o None si falla
    """
    
    print(f"\n{'='*70}")
    print(f"ğŸ›ï¸ ANALIZANDO: {site['name']}, {site['country']}")
    print(f"{'='*70}")
    print(f"ğŸ“ Coordenadas: ({site['lat']:.4f}, {site['lon']:.4f})")
    print(f"ğŸŒ Ambiente: {site['environment']}")
    print(f"ğŸ“ DescripciÃ³n: {site['description']}")
    print(f"ğŸ”¬ ESS esperado: {site['expected_ess'].upper()}")
    
    # Preparar request
    # Usar un Ã¡rea pequeÃ±a alrededor del sitio (0.01 grados â‰ˆ 1km)
    request_data = {
        "lat_min": site['lat'] - 0.01,
        "lat_max": site['lat'] + 0.01,
        "lon_min": site['lon'] - 0.01,
        "lon_max": site['lon'] + 0.01,
        "region_name": f"{site['name']}, {site['country']}"
    }
    
    try:
        print(f"\nğŸ”„ Enviando request al backend...")
        response = requests.post(
            f"{API_BASE_URL}/api/scientific/analyze",
            json=request_data,
            timeout=120  # 2 minutos timeout
        )
        
        if response.status_code != 200:
            print(f"âŒ Error HTTP {response.status_code}")
            print(f"   Response: {response.text[:200]}")
            return None
        
        result = response.json()
        
        # Extraer mÃ©tricas clave
        sci_output = result.get('scientific_output', {})
        
        print(f"\nâœ… ANÃLISIS COMPLETADO")
        print(f"\nğŸ“Š RESULTADOS:")
        print(f"   ğŸ†” Analysis ID: {sci_output.get('analysis_id')}")
        print(f"   ğŸ“ Candidate Name: {sci_output.get('candidate_name')}")
        print(f"   ğŸŒ Region: {sci_output.get('region')}")
        print(f"   ğŸï¸ Environment: {sci_output.get('environment_type')}")
        
        print(f"\nğŸ”¬ MÃ‰TRICAS CIENTÃFICAS:")
        print(f"   ğŸ“‰ Anomaly Score: {sci_output.get('anomaly_score', 0):.3f}")
        print(f"   ğŸ§¬ Anthropic Probability: {sci_output.get('anthropic_probability', 0):.3f}")
        print(f"   ğŸ“Š Confidence Interval: [{sci_output.get('confidence_interval', [0,0])[0]:.2f}, {sci_output.get('confidence_interval', [0,0])[1]:.2f}]")
        print(f"   ğŸ¯ Result Type: {sci_output.get('result_type')}")
        print(f"   âš¡ Recommended Action: {sci_output.get('recommended_action')}")
        
        print(f"\nğŸ“¡ COBERTURA INSTRUMENTAL:")
        print(f"   Raw: {sci_output.get('coverage_raw', 0):.1%} ({sci_output.get('instruments_measured', 0)}/{sci_output.get('instruments_available', 0)})")
        print(f"   Effective: {sci_output.get('coverage_effective', 0):.1%}")
        
        print(f"\nğŸ”¬ EXPLANATORY STRANGENESS:")
        ess_level = sci_output.get('explanatory_strangeness', 'none')
        ess_score = sci_output.get('strangeness_score', 0)
        ess_reasons = sci_output.get('strangeness_reasons', [])
        
        print(f"   Level: {ess_level.upper()} (score={ess_score:.3f})")
        if ess_reasons:
            print(f"   Razones:")
            for reason in ess_reasons:
                print(f"      â€¢ {reason}")
        
        # Verificar si ESS coincide con expectativa
        if ess_level in ['high', 'very_high'] and site['expected_ess'] in ['high', 'very_high']:
            print(f"\n   âœ… ESS coincide con expectativa ({site['expected_ess']})")
        elif ess_level == site['expected_ess']:
            print(f"\n   âœ… ESS coincide exactamente con expectativa")
        else:
            print(f"\n   âš ï¸ ESS difiere de expectativa (esperado: {site['expected_ess']}, obtenido: {ess_level})")
        
        print(f"\nğŸ“ EXPLICACIÃ“N:")
        explanation = sci_output.get('scientific_explanation', 'N/A')
        print(f"   {explanation[:200]}...")
        
        return result
        
    except requests.exceptions.Timeout:
        print(f"âŒ Timeout esperando respuesta del backend")
        return None
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """Analizar todos los sitios icÃ³nicos y poblar la BD."""
    
    print("\n" + "="*70)
    print("ğŸ›ï¸ ENRIQUECIMIENTO DE BASE DE DATOS")
    print("="*70)
    print(f"\nSitios a analizar: {len(ICONIC_SITES)}")
    print(f"API: {API_BASE_URL}")
    print("\nâš ï¸ IMPORTANTE: AsegÃºrate de que el backend estÃ© corriendo")
    print("   Comando: python run_archeoscope.py")
    
    input("\nâ–¶ï¸ Presiona Enter para comenzar...")
    
    results = []
    successful = 0
    failed = 0
    
    for i, site in enumerate(ICONIC_SITES, 1):
        print(f"\n\n{'#'*70}")
        print(f"# SITIO {i}/{len(ICONIC_SITES)}")
        print(f"{'#'*70}")
        
        result = analyze_site(site)
        
        if result:
            results.append({
                'site': site,
                'result': result,
                'success': True
            })
            successful += 1
        else:
            results.append({
                'site': site,
                'result': None,
                'success': False
            })
            failed += 1
        
        # Pausa entre requests para no saturar el backend
        if i < len(ICONIC_SITES):
            print(f"\nâ³ Esperando 3 segundos antes del siguiente anÃ¡lisis...")
            time.sleep(3)
    
    # Resumen final
    print("\n\n" + "="*70)
    print("ğŸ“Š RESUMEN FINAL")
    print("="*70)
    print(f"\nâœ… Exitosos: {successful}/{len(ICONIC_SITES)}")
    print(f"âŒ Fallidos: {failed}/{len(ICONIC_SITES)}")
    
    if successful > 0:
        print(f"\nğŸ‰ Base de datos enriquecida con {successful} sitios arqueolÃ³gicos icÃ³nicos")
        
        # Mostrar tabla resumen
        print(f"\nğŸ“‹ TABLA RESUMEN:")
        print(f"{'Sitio':<25} {'PaÃ­s':<15} {'ESS':<12} {'Anomaly':<10} {'Prob':<10}")
        print("-" * 70)
        
        for r in results:
            if r['success']:
                site = r['site']
                sci = r['result'].get('scientific_output', {})
                ess = sci.get('explanatory_strangeness', 'none')
                anomaly = sci.get('anomaly_score', 0)
                prob = sci.get('anthropic_probability', 0)
                
                print(f"{site['name']:<25} {site['country']:<15} {ess.upper():<12} {anomaly:<10.3f} {prob:<10.3f}")
    
    # Guardar resultados en JSON
    output_file = "iconic_sites_analysis_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Resultados guardados en: {output_file}")
    
    print("\n" + "="*70)
    print("âœ… ENRIQUECIMIENTO COMPLETADO")
    print("="*70)


if __name__ == "__main__":
    main()
