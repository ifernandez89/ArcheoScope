Documentación Completa del Hierarchical Reasoning Model (HRM)

## Índice

1. [Introducción](#introducción)
2. [Arquitectura del Modelo](#arquitectura-del-modelo)
3. [Implementación Detallada](#implementación-detallada)
4. [Dataset y Preprocesamiento](#dataset-y-preprocesamiento)
5. [Entrenamiento](#entrenamiento)
6. [Evaluación](#evaluación)
7. [Configuración](#configuración)
8. [Dependencias](#dependencias)
9. [Uso y Extensión](#uso-y-extensión)
10. [Ejemplos Prácticos](#ejemplos-prácticos)

---

## Introducción

El **Hierarchical Reasoning Model (HRM)** es una arquitectura de razonamiento jerárquico diseñada para resolver tareas complejas de razonamiento secuencial. Inspirado en el procesamiento multi-escala del cerebro humano, HRM logra un razonamiento profundo en un solo forward pass sin requerir datos de Chain-of-Thought (CoT) o pre-entrenamiento extenso.

### Características Principales

- **Razonamiento jerárquico**: Dos módulos interconectados (H y L)
- **Eficiencia**: 27 millones de parámetros con rendimiento excepcional
- **Generalización**: Funciona con pocos ejemplos (1000 muestras)
- **Versatilidad**: Resuelve Sudoku, laberintos, ARC-AGI y más

---

## Arquitectura del Modelo

### Estructura Jerárquica

```
┌─────────────────────────────────────────────────────────────┐
│                    HierarchicalReasoningModel               │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────────┐│
│  │                 H Level (High-level)                    ││
│  │  - Lento, abstracto, planificación                     ││
│  │  - 2 ciclos, 4 capas, 512 hidden                       ││
│  └─────────────────────────────────────────────────────────┘│
│  ┌─────────────────────────────────────────────────────────┐│
│  │                 L Level (Low-level)                     ││
│  │  - Rápido, detallado, computación                      ││
│  │  - 2 ciclos, 4 capas, 512 hidden                       ││
│  └─────────────────────────────────────────────────────────┘│
│  ┌─────────────────────────────────────────────────────────┐│
│  │                 Carry State                             ││
│  │  - z_H: Estado del módulo H                            ││
│  │  - z_L: Estado del módulo L                            ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────┘
```

### Módulos Principales

#### **Módulo H (High-level)**
- **Función**: Planificación lenta y abstracta
- **Características**:
  - Ejecuta menos ciclos pero con mayor profundidad
  - Genera representaciones de alto nivel
  - Responsable de la estrategia general

#### **Módulo L (Low-level)**
- **Función**: Computación rápida y detallada
- **Características**:
  - Ejecuta más ciclos con menor latencia
  - Maneja operaciones concretas y específicas
  - Implementa la estrategia definida por H

### Mecanismo de Carry

El modelo utiliza un estado de carry que permite la comunicación entre módulos:

```python
@dataclass
class HierarchicalReasoningModel_ACTV1InnerCarry:
    z_H: torch.Tensor  # Estado del módulo H
    z_L: torch.Tensor  # Estado del módulo L

@dataclass
class HierarchicalReasoningModel_ACTV1Carry:
    inner_carry: HierarchicalReasoningModel_ACTV1InnerCarry
    steps: torch.Tensor
    halted: torch.Tensor
    current_data: Dict[str, torch.Tensor]
```

### Atención y Procesamiento

Cada módulo utiliza capas de atención con incrustaciones rotativas (RoPE):

```python
class Attention(nn.Module):
    def __init__(self, hidden_size, head_dim, num_heads, num_key_value_heads, causal=False):
        # Implementación de atención con RoPE
```

---

## Implementación Detallada

### Estructura de Archivos

```
src/hrm/
├── hrm_act_v1.py          # Modelo principal
├── pretrain.py            # Entrenamiento
├── evaluate.py            # Evaluación
├── puzzle_dataset.py      # Dataset
├── dataset/
│   ├── build_sudoku_dataset.py
│   ├── build_maze_dataset.py
│   └── build_arc_dataset.py
├── models/
│   ├── common.py          # Funciones comunes
│   ├── layers.py          # Capas de atención
│   ├── losses.py          # Funciones de pérdida
│   └── sparse_embedding.py # Embeddings dispersos
├── config/
│   ├── arch/hrm_v1.yaml   # Configuración de arquitectura
│   └── cfg_pretrain.yaml  # Configuración de entrenamiento
└── requirements.txt       # Dependencias
```

### Componentes Clave

#### **1. Modelo Principal (`hrm_act_v1.py`)**

```python
class HierarchicalReasoningModel_ACTV1(nn.Module):
    def __init__(self, config_dict: dict):
        # Inicialización de la arquitectura jerárquica
        self.inner = HierarchicalReasoningModel_ACTV1_Inner(self.config)
    
    def forward(self, carry: HierarchicalReasoningModel_ACTV1Carry, batch: Dict[str, torch.Tensor]):
        # Procesamiento jerárquico
        new_inner_carry, logits, (q_halt_logits, q_continue_logits) = self.inner(new_inner_carry, new_current_data)
        return HierarchicalReasoningModel_ACTV1Carry(new_inner_carry, new_steps, halted, new_current_data), outputs
```

#### **2. Capas de Atención (`models/layers.py`)**

```python
class Attention(nn.Module):
    def forward(self, cos_sin: CosSin, hidden_states: torch.Tensor) -> torch.Tensor:
        # Aplicación de atención con RoPE
        qkv = self.qkv_proj(hidden_states)
        # Split head, apply RoPE, flash attention
        attn_output = flash_attn_func(q=query, k=key, v=value, causal=self.causal)
        return self.o_proj(attn_output)
```

#### **3. Embeddings Dispersos (`models/sparse_embedding.py`)**

```python
class CastedSparseEmbedding(nn.Module):
    def __init__(self, num_embeddings: int, embedding_dim: int, batch_size: int, init_std: float, cast_to: torch.dtype):
        # Embeddings dispersos para puzzles
        self.weights = nn.Buffer(trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std), persistent=True)
    
    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        if not self.training:
            return self.weights[inputs].to(self.cast_to)
        # Modo entrenamiento con gradientes
```

#### **4. Función de Pérdida (`models/losses.py`)**

```python
class ACTLossHead(nn.Module):
    def forward(self, return_keys: Sequence[str], **model_kwargs):
        # Cálculo de pérdida con ACT (Adaptive Computation Time)
        new_carry, loss, metrics, _, _ = self.model(carry=train_carry, batch=batch, return_keys=return_keys)
        return new_carry, lm_loss + 0.5 * (q_halt_loss + q_continue_loss), metrics
```

---

## Dataset y Preprocesamiento

### Formatos de Dataset

#### **Sudoku**
```python
# Estructura del CSV
source,q,a,rating
"extreme","53..7....6..195....98....6.8...6...34..8.3..17...2...6.6....28....419..5....8..79","534678912672195348198342567859761423426853791713924856961537284287419635345286179",9
```

#### **Laberintos**
- Representación matricial del laberinto
- Coordenadas de inicio y fin

#### **ARC-AGI**
- Formato oficial del benchmark
- Problemas de razonamiento abstracto

### Pipeline de Preprocesamiento

```python
def shuffle_sudoku(board: np.ndarray, solution: np.ndarray):
    # Augmentación mediante transformaciones dihedrales
    digit_map = np.pad(np.random.permutation(np.arange(1, 10)), (1, 0))
    transpose_flag = np.random.rand() < 0.5
    # Aplicar rotaciones, flips y mapeo de dígitos
    return apply_transformation(board), apply_transformation(solution)
```

### Clase Dataset

```python
class PuzzleDataset(IterableDataset):
    def __init__(self, config: PuzzleDatasetConfig, split: str = "train"):
        # Carga lazy de datos
        self._data = None
        self._iters = 0
    
    def _lazy_load_dataset(self):
        # Carga de archivos .npy con mmap
        for set_name in self.metadata.sets:
            self._data[set_name] = {
                field_name: np.load(os.path.join(self.config.dataset_path, self.split, f"{set_name}__{field_name}.npy"), mmap_mode=mmap_mode)
                for field_name, mmap_mode in field_mmap_modes.items()
            }
```

---

## Entrenamiento

### Configuración de Entrenamiento

```yaml
# config/cfg_pretrain.yaml
global_batch_size: 768
epochs: 100000
eval_interval: 10000
checkpoint_every_eval: True

lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 2000

beta1: 0.9
beta2: 0.95
weight_decay: 0.1
puzzle_emb_weight_decay: 0.1

puzzle_emb_lr: 1e-2
```

### Loop de Entrenamiento

```python
def train_batch(config: PretrainConfig, train_state: TrainState, batch: Any, global_batch_size: int, rank: int, world_size: int):
    # Forward pass con carry
    train_state.carry, loss, metrics, _, _ = train_state.model(carry=train_state.carry, batch=batch, return_keys=[])
    
    # Backward y optimización
    ((1 / global_batch_size) * loss).backward()
    
    # Allreduce para multi-GPU
    if world_size > 1:
        for param in train_state.model.parameters():
            if param.grad is not None:
                dist.all_reduce(param.grad)
    
    # Paso de optimizadores
    for optim, base_lr in zip(train_state.optimizers, train_state.optimizer_lrs):
        lr_this_step = compute_lr(base_lr, config, train_state)
        optim.step()
        optim.zero_grad()
```

### Optimizadores

```python
optimizers = [
    CastedSparseEmbeddingSignSGD_Distributed(
        model.model.puzzle_emb.buffers(),
        lr=0,
        weight_decay=config.puzzle_emb_weight_decay,
        world_size=world_size
    ),
    AdamATan2(
        model.parameters(),
        lr=0,
        weight_decay=config.weight_decay,
        betas=(config.beta1, config.beta2)
    )
]
```

---

## Evaluación

### Métricas Principales

```python
def evaluate(config: PretrainConfig, train_state: TrainState, eval_loader: DataLoader, eval_metadata: PuzzleDatasetMetadata, rank: int, world_size: int):
    with torch.inference_mode():
        # Evaluación sin gradientes
        carry = train_state.model.initial_carry(batch)
        
        # Forward hasta completar
        while True:
            carry, _, metrics, preds, all_finish = train_state.model(carry=carry, batch=batch, return_keys=config.eval_save_outputs)
            if all_finish:
                break
        
        # Métricas calculadas
        metrics = {
            "accuracy": torch.where(valid_metrics, (is_correct.to(torch.float32) / loss_divisor).sum(-1), 0).sum(),
            "exact_accuracy": (valid_metrics & seq_is_correct).sum(),
            "steps": torch.where(valid_metrics, new_carry.steps, 0).sum()
        }
```

### Guardado de Resultados

```python
def save_train_state(config: PretrainConfig, train_state: TrainState):
    if config.checkpoint_path is None:
        return
    
    os.makedirs(config.checkpoint_path, exist_ok=True)
    torch.save(train_state.model.state_dict(), os.path.join(config.checkpoint_path, f"step_{train_state.step}"))
    
    # Guardar predicciones
    if len(all_preds) and config.checkpoint_path is not None:
        all_preds = {k: torch.cat(v, dim=0) for k, v in all_preds.items()}
        torch.save(all_preds, os.path.join(config.checkpoint_path, f"step_{train_state.step}_all_preds.{rank}"))
```

---

## Configuración

### Configuración de Arquitectura

```yaml
# config/arch/hrm_v1.yaml
name: hrm.hrm_act_v1@HierarchicalReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

halt_exploration_prob: 0.1
halt_max_steps: 16

H_cycles: 2
L_cycles: 2

H_layers: 4
L_layers: 4

hidden_size: 512
num_heads: 8
expansion: 4

puzzle_emb_ndim: ${.hidden_size}
pos_encodings: rope
```

### Configuración de Entrenamiento

```yaml
# config/cfg_pretrain.yaml
data_path: data/arc-aug-1000
global_batch_size: 768
epochs: 100000
eval_interval: 10000

lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 2000

beta1: 0.9
beta2: 0.95
weight_decay: 0.1
puzzle_emb_weight_decay: 0.1

puzzle_emb_lr: 1e-2
```

---

## Dependencias

### Paquetes Principales

```txt
# requirements.txt
torch
adam-atan2
einops
tqdm
coolname
pydantic
argdantic
wandb
omegaconf
hydra-core
huggingface_hub
```

### Dependencias Opcionales

- **FlashAttention**: Para atención optimizada
- **CUDA**: Para aceleración GPU
- **Distributed**: Para entrenamiento multi-GPU

---

## Uso y Extensión

### Inicialización del Modelo

```python
from hrm_act_v1 import HierarchicalReasoningModel_ACTV1

config_dict = {
    "batch_size": 1,
    "seq_len": 64,
    "puzzle_emb_ndim": 0,
    "num_puzzle_identifiers": 0,
    "vocab_size": 50257,
    "H_cycles": 2,
    "L_cycles": 1,
    "H_layers": 2,
    "L_layers": 1,
    "hidden_size": 512,
    "expansion": 2,
    "num_heads": 8,
    "pos_encodings": "rope",
    "halt_max_steps": 3,
    "halt_exploration_prob": 0.05,
    "dropout_rate": 0.1
}

model = HierarchicalReasoningModel_ACTV1(config_dict=config_dict)
```

### Inferencia

```python
def generate_response(question, model, tokenizer, decoder_model):
    # Preparar prompt
    prompt = f"Pregunta: {question}\nRespuesta:"
    
    # Tokenizar
    inputs = tokenizer(prompt, return_tensors="pt", max_length=64, truncation=True)
    
    # Estado inicial
    carry = model.initial_carry({
        "inputs": inputs.input_ids,
        "puzzle_identifiers": torch.zeros(inputs.input_ids.shape[0], dtype=torch.int32)
    })
    
    # Forward pass
    carry, outputs = model(carry=carry, batch={
        "inputs": inputs.input_ids,
        "puzzle_identifiers": torch.zeros(inputs.input_ids.shape[0], dtype=torch.int32)
    })
    
    # Decodificar respuesta
    response = tokenizer.decode(outputs["logits"][0], skip_special_tokens=True)
    return response
```

### Extensión del Modelo

#### **Agregar Nuevo Módulo**

```python
class ExtendedHierarchicalReasoningModel(HierarchicalReasoningModel_ACTV1):
    def __init__(self, config_dict: dict):
        super().__init__(config_dict)
        # Agregar nuevo módulo
        self.M_level = HierarchicalReasoningModel_ACTV1ReasoningModule(
            layers=[HierarchicalReasoningModel_ACTV1Block(self.config) for _ in range(self.config.M_layers)]
        )
    
    def forward(self, carry: HierarchicalReasoningModel_ACTV1Carry, batch: Dict[str, torch.Tensor]):
        # Extender el forward con el nuevo módulo
        z_M = self.M_level(z_H + z_L, **seq_info)
        return HierarchicalReasoningModel_ACTV1Carry(new_inner_carry, new_steps, halted, new_current_data), outputs
```

#### **Cambiar Función de Pérdida**

```python
class CustomLossHead(ACTLossHead):
    def forward(self, return_keys: Sequence[str], **model_kwargs):
        # Implementar pérdida personalizada
        new_carry, loss, metrics, _, _ = self.model(**model_kwargs)
        
        # Cálculo de pérdida personalizada
        custom_loss = self.custom_loss_function(outputs["logits"], labels)
        
        return new_carry, custom_loss + 0.5 * (q_halt_loss + q_continue_loss), metrics
```

---

## Ejemplos Prácticos

### 1. Sudoku Solver

```python
def solve_sudoku(puzzle: np.ndarray, model, tokenizer):
    # Convertir puzzle a formato del modelo
    puzzle_str = ''.join(map(str, puzzle.flatten()))
    prompt = f"Sudoku:\n{puzzle_str}\nSolución:"
    
    # Generar respuesta
    response = generate_response(prompt, model, tokenizer, decoder_model)
    
    # Parsear solución
    solution = np.array(list(response)).reshape(9, 9).astype(int)
    return solution
```

### 2. Laberinto Pathfinding

```python
def find_path(maze: np.ndarray, start: tuple, end: tuple, model, tokenizer):
    # Representar laberinto como string
    maze_str = '\n'.join([''.join(row) for row in maze])
    prompt = f"Laberinto:\n{maze_str}\nInicio: {start}\nFin: {end}\nCamino:"
    
    # Obtener camino
    path = generate_response(prompt, model, tokenizer, decoder_model)
    
    # Convertir a coordenadas
    coordinates = parse_path(path)
    return coordinates
```

### 3. ARC-AGI Problem

```python
def solve_arc(problem: dict, model, tokenizer):
    # Formatear problema ARC
    prompt = format_arc_problem(problem)
    
    # Generar solución
    solution = generate_response(prompt, model, tokenizer, decoder_model)
    
    # Validar solución
    if validate_arc_solution(problem, solution):
        return solution
    else:
        return None
```

---

## Mejores Prácticas

1. **Inicialización**: Usar semillas consistentes para reproducibilidad
2. **Batch Size**: Ajustar según memoria GPU disponible
3. **Learning Rate**: Usar warmup para estabilidad
4. **Regularización**: Aplicar weight decay adecuado
5. **Monitorización**: Usar W&B para seguimiento de métricas
6. **Validación**: Evaluar con datasets de prueba separados
7. **Aumentación**: Aplicar augmentación para mejor generalización

---

## Troubleshooting

### Problemas Comunes

#### **NaN en Pérdida**
```python
# Solución: Ajustar learning rate y weight decay
config.lr = 1e-5
config.weight_decay = 0.01
```

#### **Memory Overflow**
```python
# Solución: Reducir batch size o secuencia
config.global_batch_size = 256
config.seq_len = 32
```

#### **Lento Convergencia**
```python
# Solución: Aumentar learning rate warmup
config.lr_warmup_steps = 5000
```

#### **Overfitting**
```python
# Solución: Aumentar regularización
config.weight_decay = 0.1
config.dropout_rate = 0.2
```

---

Este documento proporciona una guía completa para entender, implementar y extender el Hierarchical Reasoning Model. La arquitectura modular y bien documentada facilita su adaptación a diferentes tareas de razonamiento y entornos de producción.