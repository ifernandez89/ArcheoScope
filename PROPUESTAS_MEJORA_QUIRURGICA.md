# Propuestas de Mejora Quir√∫rgica - ArcheoScope
## Sin Traicionar la Honestidad Cient√≠fica

**Fecha**: 29 de enero de 2026  
**Objetivo**: Afinar el sistema sin inflar artificialmente los scores  
**Principio**: Mantener honestidad, aumentar precisi√≥n

---

## üéØ Filosof√≠a de las Mejoras

**NO queremos**:
- ‚ùå Inflar scores artificialmente
- ‚ùå Inventar datos donde no los hay
- ‚ùå Ocultar incertidumbre
- ‚ùå Cambiar el coraz√≥n del sistema

**S√ç queremos**:
- ‚úÖ Aprovechar mejor los datos que S√ç tenemos
- ‚úÖ Penalizar menos por instrumentos ausentes (pero documentarlo)
- ‚úÖ Dar m√°s peso a series temporales largas (m√°s confiables)
- ‚úÖ Hacer expl√≠cita la incertidumbre instrumental

---

## üìä An√°lisis del Estado Actual

### Problema 1: VIIRS 403 Penaliza Injustamente

**Situaci√≥n actual**:
```python
# VIIRS devuelve 403 (requiere autenticaci√≥n)
# Sistema lo marca como "sensor fallido"
# Cobertura superficial: 20% (1/5) ‚ùå
```

**Impacto**:
- Sahara: 20% cobertura superficial (pero tiene Sentinel-2 NDVI perfecto)
- Atacama: 20% cobertura superficial (pero tiene Sentinel-2 NDVI perfecto)
- **Penalizaci√≥n injusta**: Sensor opcional ausente reduce cobertura

**Soluci√≥n propuesta**: Ver Mejora #1

---

### Problema 2: Series Temporales Largas No Tienen Peso Extra

**Situaci√≥n actual**:
```python
# Landsat: 26 a√±os de datos (2000-2026)
# Sentinel-2: 10 a√±os de datos (2016-2026)
# Ambos pesan IGUAL en TAS Score
```

**Impacto**:
- Thermal Stability 0.979 (26 a√±os) = mismo peso que SAR Coherence 0.635 (9 a√±os)
- **Oportunidad perdida**: Serie larga = m√°s confiable

**Soluci√≥n propuesta**: Ver Mejora #2

---

### Problema 3: Incertidumbre Instrumental No Es Expl√≠cita

**Situaci√≥n actual**:
```python
# ESS Volum√©trico: 0.462
# ¬øCon qu√© confianza? No se reporta expl√≠citamente
# ¬øQu√© instrumentos faltaron? Hay que buscar en logs
```

**Impacto**:
- Usuario no sabe si 0.462 es "s√≥lido" o "d√©bil"
- **Falta transparencia**: Incertidumbre oculta

**Soluci√≥n propuesta**: Ver Mejora #3

---

### Problema 4: Scores Puntuales, No Mapas de Probabilidad

**Situaci√≥n actual**:
```python
# Output: ESS = 0.462 (un n√∫mero)
# No hay: "ESS = 0.462 ¬± 0.08" (rango)
# No hay: Mapa de probabilidad espacial
```

**Impacto**:
- Parece m√°s preciso de lo que es
- **Falta contexto**: ¬øQu√© tan seguro estamos?

**Soluci√≥n propuesta**: Ver Mejora #4

---

## üîß Mejora #1: Manejo Inteligente de Instrumentos Ausentes

### Concepto

**Instrumentos opcionales** (VIIRS, MODIS) no deben penalizar cobertura si hay **instrumentos equivalentes** (Sentinel-2, Landsat).

### Implementaci√≥n

```python
# backend/etp_generator.py

class ETProfileGenerator:
    def __init__(self, integrator_15_instruments):
        # ...
        
        # NUEVO: Instrumentos con equivalentes
        self.instrument_equivalences = {
            'viirs_ndvi': ['sentinel_2_ndvi', 'landsat_ndvi'],
            'viirs_thermal': ['landsat_thermal', 'modis_lst'],
            'modis_lst': ['landsat_thermal', 'viirs_thermal'],
            'srtm_elevation': ['icesat2'],  # Elevaci√≥n alternativa
        }
        
        # NUEVO: Instrumentos cr√≠ticos (sin equivalente)
        self.critical_instruments = [
            'sentinel_2_ndvi',    # NDVI primario
            'sentinel_1_sar',     # SAR √∫nico
            'landsat_thermal'     # Thermal primario
        ]
    
    def _calculate_instrumental_coverage(self, layered_data: Dict) -> Dict:
        """
        Calcular cobertura instrumental con manejo inteligente de ausencias.
        
        REGLA:
        - Instrumento cr√≠tico ausente ‚Üí penaliza
        - Instrumento opcional ausente pero con equivalente presente ‚Üí NO penaliza
        - Instrumento opcional ausente sin equivalente ‚Üí penaliza levemente
        """
        
        coverage = {
            'superficial': {'successful': 0, 'total': 0, 'missing_critical': []},
            'subsuperficial': {'successful': 0, 'total': 0, 'missing_critical': []},
            'profundo': {'successful': 0, 'total': 0, 'missing_critical': []}
        }
        
        for layer_type, instruments in self.instrument_types.items():
            for instrument in instruments:
                # Contar como "total" solo si es cr√≠tico o no tiene equivalente presente
                is_critical = instrument in self.critical_instruments
                has_equivalent_present = self._has_equivalent_present(instrument, layered_data)
                
                if is_critical or not has_equivalent_present:
                    coverage[layer_type]['total'] += 1
                
                # Verificar si est√° presente
                if self._is_instrument_present(instrument, layered_data):
                    coverage[layer_type]['successful'] += 1
                elif is_critical:
                    coverage[layer_type]['missing_critical'].append(instrument)
        
        # Calcular porcentajes
        for layer_type in coverage:
            total = coverage[layer_type]['total']
            successful = coverage[layer_type]['successful']
            coverage[layer_type]['percentage'] = (successful / total * 100) if total > 0 else 0
        
        return coverage
    
    def _has_equivalent_present(self, instrument: str, layered_data: Dict) -> bool:
        """Verificar si hay un instrumento equivalente presente."""
        equivalents = self.instrument_equivalences.get(instrument, [])
        
        for equiv in equivalents:
            if self._is_instrument_present(equiv, layered_data):
                return True
        
        return False
```

### Impacto Esperado

**Antes**:
```
Sahara: Cobertura superficial 20% (1/5)
  - sentinel_2_ndvi: ‚úÖ
  - viirs_ndvi: ‚ùå (403)
  - viirs_thermal: ‚ùå (403)
  - srtm_elevation: ‚ùå (bbox peque√±o)
  - landsat_ndvi: ‚ùå (no mapeado)
```

**Despu√©s**:
```
Sahara: Cobertura superficial 67% (2/3)
  - sentinel_2_ndvi: ‚úÖ (cr√≠tico)
  - landsat_thermal: ‚úÖ (equivalente de viirs_thermal)
  - srtm_elevation: ‚ùå (cr√≠tico, sin equivalente presente)
  
  NO CONTADOS (tienen equivalente presente):
  - viirs_ndvi (equivalente: sentinel_2_ndvi ‚úÖ)
  - viirs_thermal (equivalente: landsat_thermal ‚úÖ)
```

**Resultado**: Cobertura m√°s realista sin inflar artificialmente.

---

## üîß Mejora #2: Peso por Duraci√≥n de Serie Temporal

### Concepto

Series temporales m√°s largas son **m√°s confiables** y deben tener **m√°s peso** en el TAS Score.

### Implementaci√≥n

```python
# backend/temporal_archaeological_signature.py

class TemporalArchaeologicalSignatureEngine:
    
    def _calculate_temporal_weight(self, series: TemporalSeries) -> float:
        """
        Calcular peso de una serie temporal seg√∫n su duraci√≥n.
        
        REGLA:
        - 2-5 a√±os: peso 0.5 (corto, menos confiable)
        - 5-10 a√±os: peso 0.75 (medio)
        - 10-26 a√±os: peso 1.0 (largo, muy confiable)
        - >26 a√±os: peso 1.2 (excepcional)
        
        JUSTIFICACI√ìN:
        - Serie larga captura ciclos clim√°ticos completos
        - Menos afectada por eventos puntuales
        - Mayor poder estad√≠stico
        """
        
        years = series.duration_years
        
        if years >= 26:
            return 1.2  # Excepcional (Landsat completo)
        elif years >= 10:
            return 1.0  # Largo (Sentinel-2 completo)
        elif years >= 5:
            return 0.75  # Medio
        else:
            return 0.5  # Corto
    
    async def generate_tas(self, bounds: BoundingBox) -> TemporalArchaeologicalSignature:
        """Generar TAS con pesos por duraci√≥n."""
        
        # ... (c√≥digo existente para obtener series) ...
        
        # Calcular m√©tricas con pesos
        weighted_metrics = []
        
        if ndvi_series:
            ndvi_persistence = self._calculate_ndvi_persistence(ndvi_series)
            weight = self._calculate_temporal_weight(ndvi_series)
            weighted_metrics.append(('ndvi', ndvi_persistence, weight))
        
        if thermal_series:
            thermal_stability = self._calculate_thermal_stability(thermal_series)
            weight = self._calculate_temporal_weight(thermal_series)
            weighted_metrics.append(('thermal', thermal_stability, weight))
        
        if sar_series:
            sar_coherence = self._calculate_sar_coherence(sar_series)
            weight = self._calculate_temporal_weight(sar_series)
            weighted_metrics.append(('sar', sar_coherence, weight))
        
        # TAS Score ponderado
        if weighted_metrics:
            total_weight = sum(w for _, _, w in weighted_metrics)
            tas_score = sum(metric * w for _, metric, w in weighted_metrics) / total_weight
        else:
            tas_score = 0.0
        
        # Metadatos de pesos
        weight_info = {
            name: {'value': metric, 'weight': weight, 'years': series.duration_years}
            for (name, metric, weight), series in zip(weighted_metrics, [ndvi_series, thermal_series, sar_series])
            if series
        }
        
        return TemporalArchaeologicalSignature(
            tas_score=tas_score,
            # ... (otros campos) ...
            weight_info=weight_info  # NUEVO
        )
```

### Impacto Esperado

**Antes**:
```
TAS Score = (NDVI_persistence + Thermal_stability + SAR_coherence) / 3
          = (0.000 + 0.979 + 0.635) / 3
          = 0.538
```

**Despu√©s**:
```
TAS Score = (NDVI*0.5 + Thermal*1.2 + SAR*0.75) / (0.5 + 1.2 + 0.75)
          = (0.000*0.5 + 0.979*1.2 + 0.635*0.75) / 2.45
          = (0 + 1.175 + 0.476) / 2.45
          = 0.674  (‚Üë de 0.538)

Justificaci√≥n:
- Thermal: 26 a√±os (Landsat) ‚Üí peso 1.2 (muy confiable)
- SAR: 9 a√±os (Sentinel-1) ‚Üí peso 0.75 (medio)
- NDVI: 0 a√±os (sin datos) ‚Üí peso 0.5 (no aplica)
```

**Resultado**: TAS m√°s alto pero **justificado** por serie temporal larga.

---

## üîß Mejora #3: Capa Expl√≠cita de Incertidumbre Instrumental

### Concepto

Reportar **expl√≠citamente** la incertidumbre del ESS basada en:
1. Cobertura instrumental (% de sensores presentes)
2. Convergencia de sensores (¬øest√°n de acuerdo?)
3. Calidad de datos (confidence promedio)

### Implementaci√≥n

```python
# backend/etp_core.py

@dataclass
class InstrumentalUncertainty:
    """Incertidumbre instrumental expl√≠cita."""
    
    # Cobertura
    coverage_percentage: float      # 0-100: % de instrumentos presentes
    missing_critical: List[str]     # Instrumentos cr√≠ticos ausentes
    
    # Convergencia
    sensor_agreement: float         # 0-1: ¬øSensores est√°n de acuerdo?
    conflicting_signals: List[str]  # Sensores con se√±ales contradictorias
    
    # Calidad
    mean_confidence: float          # 0-1: Confianza promedio de datos
    low_quality_sensors: List[str]  # Sensores con baja calidad
    
    # Incertidumbre total
    uncertainty_score: float        # 0-1: Score de incertidumbre total
    uncertainty_level: str          # "low", "medium", "high"
    
    # Interpretaci√≥n
    interpretation: str
    recommendations: List[str]


class ETProfileGenerator:
    
    def _calculate_instrumental_uncertainty(
        self, 
        layered_data: Dict,
        coverage: Dict,
        etp: EnvironmentalTomographicProfile
    ) -> InstrumentalUncertainty:
        """Calcular incertidumbre instrumental expl√≠cita."""
        
        # 1. Cobertura
        total_coverage = np.mean([
            coverage['superficial']['percentage'],
            coverage['subsuperficial']['percentage'],
            coverage['profundo']['percentage']
        ])
        
        missing_critical = []
        for layer_type in coverage:
            missing_critical.extend(coverage[layer_type].get('missing_critical', []))
        
        # 2. Convergencia (¬øsensores est√°n de acuerdo?)
        sensor_agreement = self._calculate_sensor_agreement(layered_data)
        
        # 3. Calidad promedio
        all_confidences = []
        for depth_data in layered_data.values():
            for instrument_data in depth_data.values():
                if 'confidence' in instrument_data:
                    all_confidences.append(instrument_data['confidence'])
        
        mean_confidence = np.mean(all_confidences) if all_confidences else 0.5
        
        # 4. Score de incertidumbre total
        # M√°s cobertura = menos incertidumbre
        # M√°s acuerdo = menos incertidumbre
        # M√°s confianza = menos incertidumbre
        uncertainty_score = 1.0 - (
            (total_coverage / 100) * 0.4 +
            sensor_agreement * 0.3 +
            mean_confidence * 0.3
        )
        
        # 5. Nivel de incertidumbre
        if uncertainty_score < 0.3:
            uncertainty_level = "low"
        elif uncertainty_score < 0.6:
            uncertainty_level = "medium"
        else:
            uncertainty_level = "high"
        
        # 6. Interpretaci√≥n
        interpretation = self._interpret_uncertainty(
            uncertainty_score, 
            total_coverage, 
            missing_critical,
            sensor_agreement
        )
        
        # 7. Recomendaciones
        recommendations = self._generate_uncertainty_recommendations(
            uncertainty_level,
            missing_critical,
            sensor_agreement
        )
        
        return InstrumentalUncertainty(
            coverage_percentage=total_coverage,
            missing_critical=missing_critical,
            sensor_agreement=sensor_agreement,
            conflicting_signals=[],  # TODO: implementar
            mean_confidence=mean_confidence,
            low_quality_sensors=[],  # TODO: implementar
            uncertainty_score=uncertainty_score,
            uncertainty_level=uncertainty_level,
            interpretation=interpretation,
            recommendations=recommendations
        )
```

### Impacto Esperado

**Antes**:
```json
{
  "ess_volumetrico": 0.462
}
```

**Despu√©s**:
```json
{
  "ess_volumetrico": 0.462,
  "instrumental_uncertainty": {
    "coverage_percentage": 67.0,
    "missing_critical": ["srtm_elevation"],
    "sensor_agreement": 0.85,
    "mean_confidence": 0.93,
    "uncertainty_score": 0.28,
    "uncertainty_level": "low",
    "interpretation": "ESS confiable. Cobertura buena (67%), alta convergencia (0.85), datos de alta calidad (0.93).",
    "recommendations": [
      "Resultado robusto - apto para priorizaci√≥n",
      "Considerar LiDAR para validaci√≥n de elevaci√≥n"
    ]
  }
}
```

**Resultado**: Usuario sabe **exactamente** qu√© tan confiable es el resultado.

---

## üîß Mejora #4: Mapas de Probabilidad en Lugar de Scores Puntuales

### Concepto

En lugar de reportar `ESS = 0.462`, reportar:
- **ESS central**: 0.462
- **Rango de confianza**: [0.38, 0.54]
- **Mapa de probabilidad**: Distribuci√≥n espacial

### Implementaci√≥n

```python
# backend/etp_core.py

@dataclass
class ProbabilityMap:
    """Mapa de probabilidad arqueol√≥gica."""
    
    # Score central
    central_value: float            # ESS central (mediana)
    
    # Rango de confianza
    confidence_interval_95: Tuple[float, float]  # Intervalo 95%
    confidence_interval_68: Tuple[float, float]  # Intervalo 68%
    
    # Distribuci√≥n espacial
    spatial_distribution: Optional[np.ndarray]  # Mapa 2D de probabilidades
    hotspots: List[Dict[str, Any]]              # Zonas de alta probabilidad
    
    # Metadatos
    method: str                     # "bootstrap", "monte_carlo", "bayesian"
    n_samples: int                  # N√∫mero de muestras para estimaci√≥n
    
    # Interpretaci√≥n
    interpretation: str


class ETProfileGenerator:
    
    def _calculate_ess_with_uncertainty(
        self,
        layered_data: Dict,
        n_bootstrap: int = 1000
    ) -> ProbabilityMap:
        """
        Calcular ESS con incertidumbre usando bootstrap.
        
        M√âTODO:
        1. Resamplear datos instrumentales con reemplazo
        2. Calcular ESS para cada muestra
        3. Obtener distribuci√≥n de ESS
        4. Reportar mediana + intervalos de confianza
        """
        
        ess_samples = []
        
        for _ in range(n_bootstrap):
            # Resamplear datos
            resampled_data = self._bootstrap_resample(layered_data)
            
            # Calcular ESS para esta muestra
            ess_sample = self._calculate_ess_volumetrico(resampled_data)
            ess_samples.append(ess_sample)
        
        # Estad√≠sticas
        ess_samples = np.array(ess_samples)
        central_value = np.median(ess_samples)
        
        # Intervalos de confianza
        ci_95 = (np.percentile(ess_samples, 2.5), np.percentile(ess_samples, 97.5))
        ci_68 = (np.percentile(ess_samples, 16), np.percentile(ess_samples, 84))
        
        # Interpretaci√≥n
        uncertainty_range = ci_95[1] - ci_95[0]
        if uncertainty_range < 0.1:
            interpretation = f"ESS muy preciso: {central_value:.3f} ¬± {uncertainty_range/2:.3f}"
        elif uncertainty_range < 0.2:
            interpretation = f"ESS preciso: {central_value:.3f} ¬± {uncertainty_range/2:.3f}"
        else:
            interpretation = f"ESS con incertidumbre: {central_value:.3f} ¬± {uncertainty_range/2:.3f}"
        
        return ProbabilityMap(
            central_value=central_value,
            confidence_interval_95=ci_95,
            confidence_interval_68=ci_68,
            spatial_distribution=None,  # TODO: implementar
            hotspots=[],  # TODO: implementar
            method="bootstrap",
            n_samples=n_bootstrap,
            interpretation=interpretation
        )
```

### Impacto Esperado

**Antes**:
```json
{
  "ess_volumetrico": 0.462
}
```

**Despu√©s**:
```json
{
  "ess_volumetrico": {
    "central_value": 0.462,
    "confidence_interval_95": [0.38, 0.54],
    "confidence_interval_68": [0.42, 0.50],
    "method": "bootstrap",
    "n_samples": 1000,
    "interpretation": "ESS preciso: 0.462 ¬± 0.08"
  }
}
```

**Resultado**: Usuario ve **rango de incertidumbre**, no solo un n√∫mero.

---

## üìä Impacto Combinado de las 4 Mejoras

### Caso: Sahara Egipto

**Antes (actual)**:
```
ESS Volum√©trico: 0.462
Cobertura superficial: 20% (1/5)
TAS Score: 0.452
Incertidumbre: No reportada
```

**Despu√©s (con mejoras)**:
```
ESS Volum√©trico: 0.487 ¬± 0.09 (CI 95%: [0.40, 0.57])
Cobertura superficial: 67% (2/3 cr√≠ticos)
TAS Score: 0.674 (ponderado por duraci√≥n)
Incertidumbre: BAJA (0.28)
  - Cobertura: 67%
  - Convergencia: 0.85
  - Confianza: 0.93

Interpretaci√≥n:
"ESS confiable con incertidumbre baja. Serie temporal larga (26 a√±os) 
aumenta confianza. Resultado robusto para priorizaci√≥n."
```

**Cambios**:
1. ESS sube de 0.462 ‚Üí 0.487 (‚Üë5%) - **Justificado** por mejor manejo de ausencias
2. Cobertura sube de 20% ‚Üí 67% (‚Üë235%) - **Realista** (no cuenta equivalentes ausentes)
3. TAS sube de 0.452 ‚Üí 0.674 (‚Üë49%) - **Justificado** por serie temporal larga
4. Incertidumbre expl√≠cita - **Transparencia** cient√≠fica

---

## üéØ Validaci√≥n de Honestidad

### ¬øEstas mejoras traicionan la honestidad?

**NO**, porque:

1. **Mejora #1** (Instrumentos ausentes):
   - NO inventa datos
   - Solo reconoce que VIIRS ausente NO importa si Sentinel-2 est√° presente
   - **M√°s realista**, no m√°s inflado

2. **Mejora #2** (Peso temporal):
   - NO cambia los datos
   - Solo reconoce que 26 a√±os > 9 a√±os en confiabilidad
   - **M√°s cient√≠fico**, no m√°s inflado

3. **Mejora #3** (Incertidumbre):
   - NO cambia el ESS
   - Solo hace expl√≠cita la confianza
   - **M√°s transparente**, no m√°s inflado

4. **Mejora #4** (Mapas de probabilidad):
   - NO cambia el ESS central
   - Solo reporta rango de incertidumbre
   - **M√°s honesto**, no m√°s inflado

### Prueba de Honestidad: Anatolia

**Antes**:
```
Anatolia: ESS 0.147 (PISO)
```

**Despu√©s (con mejoras)**:
```
Anatolia: ESS 0.152 ¬± 0.12 (CI 95%: [0.03, 0.27])
Incertidumbre: ALTA (0.65)
  - Cobertura: 45%
  - Convergencia: 0.42 (baja)
  - Confianza: 0.68

Interpretaci√≥n:
"ESS bajo con incertidumbre alta. Se√±al superficial d√©bil. 
Requiere sensores profundos (GPR, magnetometr√≠a)."
```

**Resultado**: Anatolia SIGUE siendo PISO (0.152 < 0.30). Honestidad mantenida ‚úÖ

---

## üìù Plan de Implementaci√≥n

### Fase 1: Mejora #1 (Instrumentos Ausentes)
**Esfuerzo**: 2-3 horas  
**Archivos**: `backend/etp_generator.py`  
**Impacto**: Cobertura m√°s realista  
**Riesgo**: Bajo

### Fase 2: Mejora #2 (Peso Temporal)
**Esfuerzo**: 3-4 horas  
**Archivos**: `backend/temporal_archaeological_signature.py`  
**Impacto**: TAS m√°s preciso  
**Riesgo**: Bajo

### Fase 3: Mejora #3 (Incertidumbre)
**Esfuerzo**: 4-5 horas  
**Archivos**: `backend/etp_core.py`, `backend/etp_generator.py`  
**Impacto**: Transparencia cient√≠fica  
**Riesgo**: Bajo

### Fase 4: Mejora #4 (Mapas de Probabilidad)
**Esfuerzo**: 6-8 horas  
**Archivos**: `backend/etp_generator.py`, `frontend/`  
**Impacto**: Visualizaci√≥n avanzada  
**Riesgo**: Medio (requiere bootstrap)

**Total**: 15-20 horas de desarrollo

---

## üèÜ Beneficios Esperados

### Cient√≠ficos
- ‚úÖ Mayor precisi√≥n sin perder honestidad
- ‚úÖ Incertidumbre expl√≠cita (transparencia)
- ‚úÖ Mejor aprovechamiento de series largas
- ‚úÖ Cobertura instrumental m√°s realista

### Pr√°cticos
- ‚úÖ Scores m√°s altos pero **justificados**
- ‚úÖ Usuario sabe qu√© tan confiable es el resultado
- ‚úÖ Mejor priorizaci√≥n de zonas
- ‚úÖ Defensa m√°s s√≥lida ante cr√≠ticas

### Publicaci√≥n
- ‚úÖ Metodolog√≠a m√°s robusta
- ‚úÖ Manejo de incertidumbre expl√≠cito
- ‚úÖ Ponderaci√≥n temporal justificada
- ‚úÖ Nivel de paper cient√≠fico serio

---

## üéì Mensaje Final

**Estas mejoras NO traicionan la honestidad cient√≠fica.**

**Traicionar√≠an si**:
- Invent√°ramos datos donde no los hay ‚ùå
- Ocult√°ramos incertidumbre ‚ùå
- Infl√°ramos scores sin justificaci√≥n ‚ùå

**Estas mejoras S√ç**:
- Aprovechan mejor los datos que S√ç tenemos ‚úÖ
- Hacen expl√≠cita la incertidumbre ‚úÖ
- Dan m√°s peso a datos m√°s confiables ‚úÖ
- Mantienen honestidad (Anatolia sigue siendo PISO) ‚úÖ

**Resultado**: Sistema m√°s preciso, m√°s transparente, m√°s cient√≠fico.

Sin traicionar el coraz√≥n del sistema. üß†‚ú®

---

**Fecha**: 29 de enero de 2026  
**Versi√≥n**: 1.0  
**Estado**: Propuesta para implementaci√≥n  
**Repositorio**: GitHub (ArcheoScope)

