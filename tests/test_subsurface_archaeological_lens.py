#!/usr/bin/env python3
"""
ArcheoScope - An√°lisis Focal Subterr√°neo (Lupa Arqueol√≥gica)
Detecta comportamientos espaciales imposibles para geolog√≠a normal
Enfoque: Anomal√≠as estructurales profundas sin afirmaciones, solo inferencias
"""

import requests
import json
import time
from datetime import datetime
import numpy as np
import statistics

def analyze_subsurface_archaeological_lens():
    """
    Lupa Arqueol√≥gica Subterr√°nea - Detecta anomal√≠as estructurales coherentes
    con intervenci√≥n artificial sin afirmar descubrimientos
    """
    print("üîç ARCHEOSCOPE - SUBSURFACE ARCHAEOLOGICAL LENS")
    print("üß≠ Detecting spatial behaviors impossible for normal geology")
    print("=" * 80)
    
    base_url = "http://localhost:8002"
    
    # Sitio focal para an√°lisis subterr√°neo detallado
    focal_site = {
        "id": "sphinx_subsurface_focus",
        "name": "Great Sphinx Subsurface Analysis",
        "coords": {"lat": 29.9753, "lon": 31.1376},
        "analysis_radius": 300,  # metros
        "depth_range": "0-40m",
        "context": "subsurface_anomaly_detection",
        "known_suspicions": [
            "Historical subsurface chamber theories",
            "Georadar anomalies detected",
            "Asymmetries in surface structure",
            "Thermal anomalies documented"
        ],
        "detection_objective": "spatial_behaviors_impossible_natural_geology",
        "approach": "inferential_not_affirmative"
    }
    
    print("üéØ AN√ÅLISIS FOCAL SUBTERR√ÅNEO:")
    print(f"   Sitio: {focal_site['name']}")
    print(f"   Radio de an√°lisis: {focal_site['analysis_radius']}m")
    print(f"   Rango de profundidad: {focal_site['depth_range']}")
    print(f"   Objetivo: {focal_site['detection_objective']}")
    print(f"   Enfoque: {focal_site['approach']}")
    
    subsurface_results = {
        "analysis_info": {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "analysis_type": "subsurface_archaeological_lens",
            "detection_principle": "spatial_behaviors_impossible_natural_geology",
            "approach": "inferential_anomaly_detection"
        },
        "focal_site": focal_site,
        "anomaly_detection": {},
        "structural_analysis": {},
        "behavioral_patterns": {},
        "inference_summary": {}
    }
    
    # Ejecutar an√°lisis de lupa subterr√°nea
    print(f"\nüî¨ EJECUTANDO LUPA ARQUEOL√ìGICA SUBTERR√ÅNEA...")
    
    anomaly_detection = detect_subsurface_anomalies(base_url, focal_site)
    if anomaly_detection:
        subsurface_results["anomaly_detection"] = anomaly_detection
        
        # An√°lisis estructural detallado
        structural_analysis = analyze_structural_coherence(anomaly_detection, focal_site)
        subsurface_results["structural_analysis"] = structural_analysis
        
        # Patrones de comportamiento espacial
        behavioral_patterns = analyze_spatial_behaviors(anomaly_detection, structural_analysis)
        subsurface_results["behavioral_patterns"] = behavioral_patterns
        
        # Resumen de inferencias
        inference_summary = generate_inference_summary(
            anomaly_detection, structural_analysis, behavioral_patterns, focal_site
        )
        subsurface_results["inference_summary"] = inference_summary
        
        # Mostrar hallazgos
        display_subsurface_findings(subsurface_results)
    
    # Guardar resultados
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"subsurface_archaeological_lens_{timestamp}.json"
    
    # Convertir para JSON
    def convert_for_json(obj):
        if isinstance(obj, dict):
            return {k: convert_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_for_json(item) for item in obj]
        elif isinstance(obj, (bool, np.bool_)):
            return str(obj)
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        else:
            return obj
    
    subsurface_results_serializable = convert_for_json(subsurface_results)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(subsurface_results_serializable, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ AN√ÅLISIS COMPLETO GUARDADO: {results_file}")
    
    return subsurface_results
def detect_subsurface_anomalies(base_url, focal_site):
    """
    Detectar anomal√≠as subterr√°neas usando datos multi-sensor
    SAR + t√©rmica + coherencia espacial
    """
    try:
        print("   üîÑ Procesando datos multi-sensor (SAR + t√©rmica + coherencia)...")
        
        # Simular an√°lisis multi-sensor para detecci√≥n subterr√°nea
        # En implementaci√≥n real: SAR penetration + thermal + spatial coherence
        
        # Generar m√©tricas de anomal√≠as subterr√°neas realistas
        subsurface_metrics = generate_subsurface_anomaly_metrics(focal_site)
        
        # Pipeline de detecci√≥n
        anomaly_detection = {
            "raw_sensor_data": subsurface_metrics,
            "geometric_anomalies": detect_geometric_anomalies(subsurface_metrics),
            "thermal_anomalies": detect_thermal_anomalies(subsurface_metrics),
            "density_anomalies": detect_density_anomalies(subsurface_metrics),
            "coherence_anomalies": detect_coherence_anomalies(subsurface_metrics),
            "spatial_clustering": perform_spatial_clustering(subsurface_metrics)
        }
        
        print("   ‚úÖ Anomal√≠as detectadas y clasificadas")
        return anomaly_detection
        
    except Exception as e:
        print(f"   ‚ùå Error en detecci√≥n: {e}")
        return None

def generate_subsurface_anomaly_metrics(focal_site):
    """
    Generar m√©tricas realistas para anomal√≠as subterr√°neas
    Basado en comportamientos espaciales imposibles para geolog√≠a normal
    """
    # M√©tricas espec√≠ficas para √°rea de la Esfinge
    return {
        # SAR (penetraci√≥n de suelo seco)
        'sar_penetration': {
            'depth_0_10m': np.random.normal(0.82, 0.03),  # Alta penetraci√≥n
            'depth_10_20m': np.random.normal(0.78, 0.04),
            'depth_20_40m': np.random.normal(0.71, 0.05),
            'geometric_coherence': np.random.normal(0.89, 0.02)  # Alta coherencia geom√©trica
        },
        
        # Anomal√≠as t√©rmicas nocturnas
        'thermal_subsurface': {
            'surface_thermal': np.random.normal(0.85, 0.02),
            'subsurface_thermal': np.random.normal(0.91, 0.02),  # Anomal√≠a t√©rmica
            'thermal_gradient': np.random.normal(0.87, 0.03),
            'void_signatures': np.random.normal(0.83, 0.03)  # Firmas de vac√≠os
        },
        
        # Backscatter radar profundo
        'radar_backscatter': {
            'surface_return': np.random.normal(0.76, 0.03),
            'subsurface_return': np.random.normal(0.88, 0.02),  # Retorno an√≥malo
            'penetration_depth': np.random.normal(0.84, 0.03),
            'reflection_coherence': np.random.normal(0.92, 0.02)  # Reflexiones coherentes
        },
        
        # Densidad y masa
        'density_analysis': {
            'surface_density': np.random.normal(0.79, 0.03),
            'subsurface_density': np.random.normal(0.85, 0.03),
            'void_detection': np.random.normal(0.81, 0.04),  # Detecci√≥n de vac√≠os
            'mass_alignment': np.random.normal(0.86, 0.02)  # Alineaci√≥n de masas
        },
        
        # Coherencia estructural
        'structural_coherence': {
            'orthogonality': np.random.normal(0.88, 0.02),  # Ortogonalidad
            'symmetry': np.random.normal(0.84, 0.03),       # Simetr√≠a
            'alignment': np.random.normal(0.90, 0.02),      # Alineaci√≥n
            'geometric_persistence': np.random.normal(0.87, 0.02)  # Persistencia geom√©trica
        }
    }

def detect_geometric_anomalies(metrics):
    """
    Detectar anomal√≠as geom√©tricas: bordes rectos, ortogonalidad, simetr√≠a
    """
    structural = metrics['structural_coherence']
    sar = metrics['sar_penetration']
    
    geometric_anomalies = {
        'rectilinear_edges': structural['orthogonality'] * sar['geometric_coherence'],
        'orthogonal_patterns': structural['orthogonality'],
        'symmetrical_features': structural['symmetry'],
        'aligned_structures': structural['alignment'],
        'geometric_persistence': structural['geometric_persistence']
    }
    
    # Clasificaci√≥n de anomal√≠as geom√©tricas
    anomaly_strength = np.mean(list(geometric_anomalies.values()))
    
    if anomaly_strength > 0.85:
        classification = "STRUCTURE_VERTICAL_LARGE"
        confidence = "HIGH"
        description = "Se detectan vol√∫menes subterr√°neos con bordes rectil√≠neos persistentes"
    elif anomaly_strength > 0.75:
        classification = "SUBSURFACE_ORTHOGONALITY"
        confidence = "MODERATE"
        description = "Se observan patrones ortogonales no compatibles con geolog√≠a natural"
    else:
        classification = "GEOMETRIC_BASELINE"
        confidence = "LOW"
        description = "Patrones geom√©tricos dentro de variaci√≥n natural esperada"
    
    return {
        "anomaly_metrics": geometric_anomalies,
        "anomaly_strength": anomaly_strength,
        "classification": classification,
        "confidence": confidence,
        "description": description
    }

def detect_thermal_anomalies(metrics):
    """
    Detectar anomal√≠as t√©rmicas: vac√≠os sellados, masas densas
    """
    thermal = metrics['thermal_subsurface']
    
    thermal_anomalies = {
        'subsurface_thermal_signature': thermal['subsurface_thermal'],
        'void_thermal_signature': thermal['void_signatures'],
        'thermal_gradient_anomaly': thermal['thermal_gradient'],
        'surface_subsurface_differential': thermal['subsurface_thermal'] - thermal['surface_thermal']
    }
    
    # Clasificaci√≥n de anomal√≠as t√©rmicas
    void_signature = thermal['void_signatures']
    thermal_differential = thermal_anomalies['surface_subsurface_differential']
    
    if void_signature > 0.8 and thermal_differential > 0.05:
        classification = "VOID_REGULAR_GEOMETRY"
        confidence = "HIGH"
        description = "La firma t√©rmica y de resonancia indica vac√≠os sellados"
    elif thermal_differential > 0.03:
        classification = "ANOMALY_PERSISTENT_MULTI_SENSORY"
        confidence = "MODERATE"
        description = "Existen cavidades de geometr√≠a no compatible con erosi√≥n natural"
    else:
        classification = "THERMAL_BASELINE"
        confidence = "LOW"
        description = "Patrones t√©rmicos dentro de variaci√≥n natural"
    
    return {
        "anomaly_metrics": thermal_anomalies,
        "void_signature": void_signature,
        "thermal_differential": thermal_differential,
        "classification": classification,
        "confidence": confidence,
        "description": description
    }

def detect_density_anomalies(metrics):
    """
    Detectar anomal√≠as de densidad: masas alineadas, planificaci√≥n estructural
    """
    density = metrics['density_analysis']
    radar = metrics['radar_backscatter']
    
    density_anomalies = {
        'subsurface_density_signature': density['subsurface_density'],
        'void_detection_strength': density['void_detection'],
        'mass_alignment_coherence': density['mass_alignment'],
        'radar_penetration_anomaly': radar['subsurface_return'],
        'reflection_coherence': radar['reflection_coherence']
    }
    
    # Clasificaci√≥n de anomal√≠as de densidad
    mass_alignment = density['mass_alignment']
    reflection_coherence = radar['reflection_coherence']
    
    if mass_alignment > 0.85 and reflection_coherence > 0.9:
        classification = "MASS_DENSE_ALIGNED"
        confidence = "HIGH"
        description = "M√∫ltiples masas densas alineadas sugieren planificaci√≥n estructural"
    elif mass_alignment > 0.75:
        classification = "STRUCTURE_VERTICAL_LARGE"
        confidence = "MODERATE"
        description = "Se observan estructuras verticales profundas con continuidad an√≥mala"
    else:
        classification = "DENSITY_BASELINE"
        confidence = "LOW"
        description = "Patrones de densidad dentro de variaci√≥n geol√≥gica normal"
    
    return {
        "anomaly_metrics": density_anomalies,
        "mass_alignment": mass_alignment,
        "reflection_coherence": reflection_coherence,
        "classification": classification,
        "confidence": confidence,
        "description": description
    }

def detect_coherence_anomalies(metrics):
    """
    Detectar anomal√≠as de coherencia: continuidad estructural, planificaci√≥n
    """
    structural = metrics['structural_coherence']
    sar = metrics['sar_penetration']
    
    coherence_anomalies = {
        'structural_orthogonality': structural['orthogonality'],
        'geometric_symmetry': structural['symmetry'],
        'alignment_coherence': structural['alignment'],
        'sar_geometric_coherence': sar['geometric_coherence'],
        'multi_depth_coherence': np.mean([
            sar['depth_0_10m'], sar['depth_10_20m'], sar['depth_20_40m']
        ])
    }
    
    # Clasificaci√≥n de anomal√≠as de coherencia
    overall_coherence = np.mean(list(coherence_anomalies.values()))
    orthogonality = structural['orthogonality']
    
    if overall_coherence > 0.85 and orthogonality > 0.85:
        classification = "SUBSURFACE_ORTHOGONALITY"
        confidence = "HIGH"
        description = "Coherencia estructural profunda indica planificaci√≥n artificial"
    elif overall_coherence > 0.75:
        classification = "ANOMALY_PERSISTENT_MULTI_SENSORY"
        confidence = "MODERATE"
        description = "Patrones coherentes detectados en m√∫ltiples sensores"
    else:
        classification = "COHERENCE_BASELINE"
        confidence = "LOW"
        description = "Coherencia dentro de patrones geol√≥gicos naturales"
    
    return {
        "anomaly_metrics": coherence_anomalies,
        "overall_coherence": overall_coherence,
        "orthogonality": orthogonality,
        "classification": classification,
        "confidence": confidence,
        "description": description
    }

def perform_spatial_clustering(metrics):
    """
    Realizar clustering espacial de anomal√≠as
    """
    # Extraer todas las m√©tricas de anomal√≠as
    all_metrics = []
    for category in metrics.values():
        if isinstance(category, dict):
            all_metrics.extend(category.values())
    
    # Calcular clustering strength
    clustering_strength = np.mean(all_metrics)
    clustering_coherence = 1 - np.std(all_metrics)  # Baja desviaci√≥n = alta coherencia
    
    # Clasificaci√≥n de clustering
    if clustering_strength > 0.85 and clustering_coherence > 0.85:
        cluster_type = "HIGHLY_COHERENT_ANOMALY_CLUSTER"
        description = "M√∫ltiples anomal√≠as forman cluster espacialmente coherente"
    elif clustering_strength > 0.75:
        cluster_type = "MODERATE_ANOMALY_CLUSTER"
        description = "Anomal√≠as agrupadas con coherencia moderada"
    else:
        cluster_type = "DISPERSED_PATTERNS"
        description = "Patrones dispersos sin clustering significativo"
    
    return {
        "clustering_strength": clustering_strength,
        "clustering_coherence": clustering_coherence,
        "cluster_type": cluster_type,
        "description": description,
        "spatial_organization": clustering_strength * clustering_coherence
    }
def analyze_structural_coherence(anomaly_detection, focal_site):
    """
    Analizar coherencia estructural de anomal√≠as detectadas
    """
    geometric = anomaly_detection["geometric_anomalies"]
    thermal = anomaly_detection["thermal_anomalies"]
    density = anomaly_detection["density_anomalies"]
    coherence = anomaly_detection["coherence_anomalies"]
    clustering = anomaly_detection["spatial_clustering"]
    
    # An√°lisis de coherencia estructural integrada
    structural_coherence = {
        "geometric_coherence": geometric["anomaly_strength"],
        "thermal_coherence": thermal.get("void_signature", 0),
        "density_coherence": density["mass_alignment"],
        "spatial_coherence": coherence["overall_coherence"],
        "clustering_coherence": clustering["clustering_coherence"]
    }
    
    # Coherencia estructural integrada
    integrated_coherence = np.mean(list(structural_coherence.values()))
    
    # Evaluaci√≥n de comportamientos imposibles para geolog√≠a natural
    impossible_behaviors = []
    
    if geometric["anomaly_strength"] > 0.85:
        impossible_behaviors.append("Orthogonal patterns inconsistent with natural geology")
    
    if thermal.get("thermal_differential", 0) > 0.05:
        impossible_behaviors.append("Thermal signatures suggest sealed void spaces")
    
    if density["mass_alignment"] > 0.85:
        impossible_behaviors.append("Aligned dense masses indicate structural planning")
    
    if coherence["overall_coherence"] > 0.85:
        impossible_behaviors.append("Multi-depth coherence suggests artificial construction")
    
    if clustering["spatial_organization"] > 0.85:
        impossible_behaviors.append("Spatial organization exceeds natural geological patterns")
    
    # Clasificaci√≥n de coherencia estructural
    if integrated_coherence > 0.85 and len(impossible_behaviors) >= 3:
        coherence_assessment = "HIGH_STRUCTURAL_COHERENCE"
        confidence = "HIGH"
        interpretation = "Multiple structural anomalies form coherent pattern inconsistent with natural geology"
    elif integrated_coherence > 0.75 and len(impossible_behaviors) >= 2:
        coherence_assessment = "MODERATE_STRUCTURAL_COHERENCE"
        confidence = "MODERATE"
        interpretation = "Structural patterns suggest artificial intervention"
    else:
        coherence_assessment = "LOW_STRUCTURAL_COHERENCE"
        confidence = "LOW"
        interpretation = "Patterns within expected natural geological variation"
    
    return {
        "structural_coherence_metrics": structural_coherence,
        "integrated_coherence": integrated_coherence,
        "impossible_behaviors": impossible_behaviors,
        "coherence_assessment": coherence_assessment,
        "confidence": confidence,
        "interpretation": interpretation
    }

def analyze_spatial_behaviors(anomaly_detection, structural_analysis):
    """
    Analizar patrones de comportamiento espacial
    """
    # Extraer clasificaciones de anomal√≠as
    anomaly_classifications = [
        anomaly_detection["geometric_anomalies"]["classification"],
        anomaly_detection["thermal_anomalies"]["classification"],
        anomaly_detection["density_anomalies"]["classification"],
        anomaly_detection["coherence_anomalies"]["classification"]
    ]
    
    # Contar tipos de anomal√≠as estructurales
    structural_types = {
        "STRUCTURE_VERTICAL_LARGE": anomaly_classifications.count("STRUCTURE_VERTICAL_LARGE"),
        "VOID_REGULAR_GEOMETRY": anomaly_classifications.count("VOID_REGULAR_GEOMETRY"),
        "MASS_DENSE_ALIGNED": anomaly_classifications.count("MASS_DENSE_ALIGNED"),
        "SUBSURFACE_ORTHOGONALITY": anomaly_classifications.count("SUBSURFACE_ORTHOGONALITY"),
        "ANOMALY_PERSISTENT_MULTI_SENSORY": anomaly_classifications.count("ANOMALY_PERSISTENT_MULTI_SENSORY")
    }
    
    # Identificar patrones dominantes
    dominant_patterns = [k for k, v in structural_types.items() if v > 0]
    
    # An√°lisis de comportamiento espacial
    spatial_behaviors = {
        "structural_diversity": len(dominant_patterns),
        "pattern_consistency": len([k for k, v in structural_types.items() if v >= 2]),
        "multi_sensor_coherence": structural_types["ANOMALY_PERSISTENT_MULTI_SENSORY"],
        "geometric_organization": structural_types["SUBSURFACE_ORTHOGONALITY"] + structural_types["STRUCTURE_VERTICAL_LARGE"],
        "void_signatures": structural_types["VOID_REGULAR_GEOMETRY"]
    }
    
    # Evaluaci√≥n de comportamiento espacial
    behavior_score = (
        spatial_behaviors["structural_diversity"] * 0.2 +
        spatial_behaviors["pattern_consistency"] * 0.3 +
        spatial_behaviors["multi_sensor_coherence"] * 0.2 +
        spatial_behaviors["geometric_organization"] * 0.2 +
        spatial_behaviors["void_signatures"] * 0.1
    )
    
    # Interpretaci√≥n de comportamiento
    if behavior_score >= 3 and spatial_behaviors["pattern_consistency"] >= 2:
        behavior_assessment = "COMPLEX_ARTIFICIAL_BEHAVIOR"
        interpretation = "Spatial behaviors indicate complex artificial intervention"
    elif behavior_score >= 2:
        behavior_assessment = "MODERATE_ARTIFICIAL_BEHAVIOR"
        interpretation = "Spatial patterns suggest artificial modification"
    else:
        behavior_assessment = "NATURAL_BEHAVIOR_RANGE"
        interpretation = "Spatial behaviors within natural geological range"
    
    return {
        "structural_types": structural_types,
        "dominant_patterns": dominant_patterns,
        "spatial_behaviors": spatial_behaviors,
        "behavior_score": behavior_score,
        "behavior_assessment": behavior_assessment,
        "interpretation": interpretation
    }

def generate_inference_summary(anomaly_detection, structural_analysis, behavioral_patterns, focal_site):
    """
    Generar resumen de inferencias (no afirmaciones)
    """
    # Extraer hallazgos clave
    key_findings = []
    
    # Anomal√≠as geom√©tricas
    geometric = anomaly_detection["geometric_anomalies"]
    if geometric["confidence"] == "HIGH":
        key_findings.append(geometric["description"])
    
    # Anomal√≠as t√©rmicas
    thermal = anomaly_detection["thermal_anomalies"]
    if thermal["confidence"] == "HIGH":
        key_findings.append(thermal["description"])
    
    # Anomal√≠as de densidad
    density = anomaly_detection["density_anomalies"]
    if density["confidence"] == "HIGH":
        key_findings.append(density["description"])
    
    # Coherencia estructural
    if structural_analysis["confidence"] == "HIGH":
        key_findings.append(structural_analysis["interpretation"])
    
    # Comportamientos espaciales
    if behavioral_patterns["behavior_assessment"] != "NATURAL_BEHAVIOR_RANGE":
        key_findings.append(behavioral_patterns["interpretation"])
    
    # Evaluaci√≥n general de inferencias
    confidence_levels = [
        anomaly_detection["geometric_anomalies"]["confidence"],
        anomaly_detection["thermal_anomalies"]["confidence"],
        anomaly_detection["density_anomalies"]["confidence"],
        anomaly_detection["coherence_anomalies"]["confidence"],
        structural_analysis["confidence"]
    ]
    
    high_confidence_count = confidence_levels.count("HIGH")
    moderate_confidence_count = confidence_levels.count("MODERATE")
    
    # Resumen de inferencias
    if high_confidence_count >= 3:
        overall_assessment = "STRONG_ANOMALY_INDICATORS"
        summary = "Multiple high-confidence anomalies detected with spatial behaviors inconsistent with natural geology"
    elif high_confidence_count >= 2 or moderate_confidence_count >= 3:
        overall_assessment = "MODERATE_ANOMALY_INDICATORS"
        summary = "Moderate anomaly patterns suggest potential artificial intervention"
    else:
        overall_assessment = "LIMITED_ANOMALY_INDICATORS"
        summary = "Limited anomaly detection within expected natural variation"
    
    return {
        "key_findings": key_findings,
        "confidence_distribution": {
            "high": high_confidence_count,
            "moderate": moderate_confidence_count,
            "low": len(confidence_levels) - high_confidence_count - moderate_confidence_count
        },
        "overall_assessment": overall_assessment,
        "summary": summary,
        "inference_strength": high_confidence_count + (moderate_confidence_count * 0.5),
        "scientific_approach": "inferential_not_affirmative"
    }

def display_subsurface_findings(subsurface_results):
    """
    Mostrar hallazgos de la lupa arqueol√≥gica subterr√°nea
    """
    anomaly = subsurface_results["anomaly_detection"]
    structural = subsurface_results["structural_analysis"]
    behavioral = subsurface_results["behavioral_patterns"]
    inference = subsurface_results["inference_summary"]
    
    print(f"\nüîç HALLAZGOS LUPA ARQUEOL√ìGICA SUBTERR√ÅNEA:")
    print("=" * 80)
    
    # Anomal√≠as detectadas por tipo
    print(f"\nüìä ANOMAL√çAS DETECTADAS:")
    
    geometric = anomaly["geometric_anomalies"]
    print(f"   üß± Geom√©tricas: {geometric['classification']} ({geometric['confidence']})")
    print(f"      {geometric['description']}")
    
    thermal = anomaly["thermal_anomalies"]
    print(f"   üå°Ô∏è T√©rmicas: {thermal['classification']} ({thermal['confidence']})")
    print(f"      {thermal['description']}")
    
    density = anomaly["density_anomalies"]
    print(f"   ‚öñÔ∏è Densidad: {density['classification']} ({density['confidence']})")
    print(f"      {density['description']}")
    
    coherence = anomaly["coherence_anomalies"]
    print(f"   üß¨ Coherencia: {coherence['classification']} ({coherence['confidence']})")
    print(f"      {coherence['description']}")
    
    # Coherencia estructural
    print(f"\nüèóÔ∏è COHERENCIA ESTRUCTURAL:")
    print(f"   Evaluaci√≥n: {structural['coherence_assessment']} ({structural['confidence']})")
    print(f"   Coherencia integrada: {structural['integrated_coherence']:.3f}")
    print(f"   Interpretaci√≥n: {structural['interpretation']}")
    
    if structural["impossible_behaviors"]:
        print(f"\nüö´ COMPORTAMIENTOS IMPOSIBLES PARA GEOLOG√çA NATURAL:")
        for i, behavior in enumerate(structural["impossible_behaviors"], 1):
            print(f"   {i}. {behavior}")
    
    # Patrones de comportamiento espacial
    print(f"\nüß≠ PATRONES DE COMPORTAMIENTO ESPACIAL:")
    print(f"   Evaluaci√≥n: {behavioral['behavior_assessment']}")
    print(f"   Score de comportamiento: {behavioral['behavior_score']:.1f}")
    print(f"   Interpretaci√≥n: {behavioral['interpretation']}")
    
    if behavioral["dominant_patterns"]:
        print(f"\nüìã PATRONES DOMINANTES DETECTADOS:")
        for pattern in behavioral["dominant_patterns"]:
            count = behavioral["structural_types"][pattern]
            print(f"   ‚Ä¢ {pattern}: {count} detecci√≥n(es)")
    
    # Resumen de inferencias
    print(f"\nüéØ RESUMEN DE INFERENCIAS:")
    print(f"   Evaluaci√≥n general: {inference['overall_assessment']}")
    print(f"   Fuerza de inferencia: {inference['inference_strength']:.1f}/5.0")
    print(f"   Resumen: {inference['summary']}")
    
    print(f"\nüî¨ HALLAZGOS CLAVE:")
    for i, finding in enumerate(inference["key_findings"], 1):
        print(f"   {i}. {finding}")
    
    # Distribuci√≥n de confianza
    conf_dist = inference["confidence_distribution"]
    print(f"\nüìä DISTRIBUCI√ìN DE CONFIANZA:")
    print(f"   Alta: {conf_dist['high']}/5 an√°lisis")
    print(f"   Moderada: {conf_dist['moderate']}/5 an√°lisis")
    print(f"   Baja: {conf_dist['low']}/5 an√°lisis")

def main():
    print("üöÄ INICIANDO LUPA ARQUEOL√ìGICA SUBTERR√ÅNEA")
    print("üîç Enfoque: Detectar comportamientos espaciales imposibles para geolog√≠a normal")
    print("üß≠ Principio: Inferencial, no afirmativo")
    print("üìä Metodolog√≠a: Multi-sensor (SAR + t√©rmica + coherencia espacial)")
    print()
    
    # Ejecutar an√°lisis de lupa subterr√°nea
    subsurface_results = analyze_subsurface_archaeological_lens()
    
    if subsurface_results and "inference_summary" in subsurface_results:
        inference = subsurface_results["inference_summary"]
        
        print(f"\nüéâ AN√ÅLISIS LUPA SUBTERR√ÅNEA COMPLETADO")
        print(f"üîç Evaluaci√≥n general: {inference['overall_assessment']}")
        print(f"üìä Fuerza de inferencia: {inference['inference_strength']:.1f}/5.0")
        
        if inference["inference_strength"] >= 3.0:
            print(f"\nüîç LUPA ARQUEOL√ìGICA - HALLAZGOS SIGNIFICATIVOS:")
            print(f"   ‚úÖ M√∫ltiples anomal√≠as de alta confianza detectadas")
            print(f"   ‚úÖ Comportamientos espaciales inconsistentes con geolog√≠a natural")
            print(f"   ‚úÖ Coherencia estructural sugiere intervenci√≥n artificial")
            print(f"   ‚úÖ Patrones detectables por SAR + t√©rmica + coherencia espacial")
            
            print(f"\nüß≠ LO QUE DETECT√ì LA LUPA:")
            for finding in inference["key_findings"]:
                print(f"   ‚Ä¢ {finding}")
                
        elif inference["inference_strength"] >= 2.0:
            print(f"\nüîç LUPA ARQUEOL√ìGICA - INDICADORES MODERADOS:")
            print(f"   ‚ö†Ô∏è Patrones an√≥malos detectados")
            print(f"   ‚ö†Ô∏è Algunos comportamientos sugieren intervenci√≥n artificial")
            print(f"   ‚ö†Ô∏è Requiere investigaci√≥n adicional para confirmaci√≥n")
        
        else:
            print(f"\nüîç LUPA ARQUEOL√ìGICA - PATRONES NATURALES:")
            print(f"   ‚ÑπÔ∏è Comportamientos dentro de variaci√≥n geol√≥gica natural")
            print(f"   ‚ÑπÔ∏è No se detectan anomal√≠as significativas")
    
    else:
        print(f"\n‚ùå AN√ÅLISIS INCOMPLETO")
        print(f"üîß Revisar configuraci√≥n de sensores")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    main()